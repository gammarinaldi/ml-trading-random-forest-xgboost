import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
import pandas as pd
import numpy as np
import os
import warnings
warnings.filterwarnings('ignore')

from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_squared_error, r2_score, accuracy_score
import matplotlib
matplotlib.use('Agg')
import matplotlib.pyplot as plt
from tqdm import tqdm
import time
import json
import math
import random
from typing import List, Dict, Tuple, Optional

# Additional imports for medium-impact optimizations
import torch.nn.functional as F
from torch.nn.utils import spectral_norm
from torch.utils.checkpoint import checkpoint
import onnx
import onnxruntime as ort

# Quick Performance Optimizations
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
print(f"üéÆ PyTorch Device: {device}")
if torch.cuda.is_available():
    print(f"‚úÖ GPU: {torch.cuda.get_device_name(0)}")
    print(f"üöÄ GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB")
    print(f"üî• CUDA Version: {torch.version.cuda}")
    # Performance optimizations
    torch.backends.cudnn.benchmark = True  # Optimize for fixed input sizes
    torch.backends.cudnn.deterministic = False  # Allow non-deterministic for speed
else:
    print("‚ùå CUDA not available")

torch.manual_seed(42)
np.random.seed(42)
random.seed(42)

# Enable mixed precision training for RTX 3060
from torch.cuda.amp import autocast, GradScaler
use_amp = torch.cuda.is_available()  # Automatic Mixed Precision
scaler = GradScaler() if use_amp else None

# ========== NEW OPTIMIZATION CLASSES ==========

class EarlyStopping:
    """Early stopping to prevent overfitting"""
    def __init__(self, patience=7, min_delta=0.0001, restore_best_weights=True):
        self.patience = patience
        self.min_delta = min_delta
        self.restore_best_weights = restore_best_weights
        self.best_loss = float('inf')
        self.counter = 0
        self.best_weights = None
        
    def __call__(self, val_loss, model):
        if val_loss < self.best_loss - self.min_delta:
            self.best_loss = val_loss
            self.counter = 0
            if self.restore_best_weights:
                self.best_weights = model.state_dict().copy()
        else:
            self.counter += 1
            
        if self.counter >= self.patience:
            if self.restore_best_weights and self.best_weights is not None:
                model.load_state_dict(self.best_weights)
            return True
        return False

class LearningRateFinder:
    """Find optimal learning rate automatically"""
    def __init__(self, model, optimizer, criterion, device):
        self.model = model
        self.optimizer = optimizer
        self.criterion = criterion
        self.device = device
        
    def find_lr(self, train_loader, init_lr=1e-8, final_lr=10, beta=0.98, num_iter=100):
        """Find optimal learning rate using exponential range test"""
        print("üîç Finding optimal learning rate...")
        
        # Save initial state
        model_state = self.model.state_dict()
        optim_state = self.optimizer.state_dict()
        
        # Setup
        lr_mult = (final_lr / init_lr) ** (1 / num_iter)
        lr = init_lr
        losses = []
        lrs = []
        best_loss = float('inf')
        
        # Set initial learning rate
        for param_group in self.optimizer.param_groups:
            param_group['lr'] = lr
            
        self.model.train()
        iterator = iter(train_loader)
        
        for i in range(min(num_iter, len(train_loader))):
            try:
                X_batch, y_direction_batch, y_price_batch = next(iterator)
            except StopIteration:
                break
                
            X_batch = X_batch.to(self.device, non_blocking=True)
            y_direction_batch = y_direction_batch.to(self.device, non_blocking=True)
            y_price_batch = y_price_batch.to(self.device, non_blocking=True)
            
            # Forward pass
            self.optimizer.zero_grad()
            
            if use_amp:
                with autocast():
                    direction_outputs, price_outputs, dir_unc, price_unc = self.model(X_batch)
                    direction_loss = nn.CrossEntropyLoss()(direction_outputs, y_direction_batch)
                    price_loss = nn.MSELoss()(price_outputs.squeeze(), y_price_batch)
                    loss = direction_loss + 0.1 * price_loss
                scaler.scale(loss).backward()
                scaler.step(self.optimizer)
                scaler.update()
            else:
                direction_outputs, price_outputs, dir_unc, price_unc = self.model(X_batch)
                direction_loss = nn.CrossEntropyLoss()(direction_outputs, y_direction_batch)
                price_loss = nn.MSELoss()(price_outputs.squeeze(), y_price_batch)
                loss = direction_loss + 0.1 * price_loss
                loss.backward()
                self.optimizer.step()
            
            # Smooth loss
            if i == 0:
                smooth_loss = loss.item()
            else:
                smooth_loss = beta * smooth_loss + (1 - beta) * loss.item()
                
            # Stop if loss explodes
            if smooth_loss < best_loss:
                best_loss = smooth_loss
            elif smooth_loss > 4 * best_loss:
                break
                
            # Store values
            losses.append(smooth_loss)
            lrs.append(lr)
            
            # Update learning rate
            lr *= lr_mult
            for param_group in self.optimizer.param_groups:
                param_group['lr'] = lr
                
            # Memory cleanup for RTX 3060
            if torch.cuda.is_available():
                torch.cuda.empty_cache()
        
        # Restore initial state
        self.model.load_state_dict(model_state)
        self.optimizer.load_state_dict(optim_state)
        
        # Find optimal LR (steepest descent)
        if len(losses) > 10:
            # Find the steepest point
            gradients = np.gradient(losses)
            optimal_idx = np.argmin(gradients)
            optimal_lr = lrs[optimal_idx]
            
            # Use 10x lower than steepest point for safety, but clamp to reasonable range
            suggested_lr = optimal_lr / 10
            
            # Clamp learning rate to conservative range for financial data stability
            suggested_lr = max(1e-6, min(5e-4, suggested_lr))
            
            print(f"üìà LR Finder Results:")
            print(f"   Steepest descent at: {optimal_lr:.2e}")
            print(f"   Suggested LR: {suggested_lr:.2e} (clamped)")
            
            return suggested_lr
        else:
            print("‚ö†Ô∏è Not enough data points for LR finder, using default")
            return 0.001

# ========== EXISTING CLASSES (UNCHANGED) ==========

class ForexDataset(Dataset):
    def __init__(self, X, y_direction, y_price):
        self.X = torch.FloatTensor(X)
        self.y_direction = torch.LongTensor(y_direction)
        self.y_price = torch.FloatTensor(y_price)
        
    def __len__(self):
        return len(self.X)
    
    def __getitem__(self, idx):
        return self.X[idx], self.y_direction[idx], self.y_price[idx]

class RTX3060ForexNet(nn.Module):
    """Advanced LSTM-based Network for RTX 3060"""
    def __init__(self, input_size, n_timesteps=100, num_classes=3, dropout=0.3):
        super(RTX3060ForexNet, self).__init__()
        
        # Calculate feature dimension
        self.n_features = input_size // n_timesteps
        self.n_timesteps = n_timesteps
        
        # LSTM layers for temporal patterns
        self.lstm1 = nn.LSTM(
            input_size=self.n_features,
            hidden_size=128,
            num_layers=2,
            batch_first=True,
            dropout=dropout,
            bidirectional=True
        )
        
        self.lstm2 = nn.LSTM(
            input_size=256,  # bidirectional = 128*2
            hidden_size=64,
            num_layers=1,
            batch_first=True,
            dropout=dropout
        )
        
        # Attention mechanism
        self.attention = nn.MultiheadAttention(
            embed_dim=64,
            num_heads=8,
            dropout=dropout,
            batch_first=True
        )
        
        # Shared feature extractor
        self.shared_head = nn.Sequential(
            nn.Linear(64, 128),
            nn.BatchNorm1d(128),
            nn.ReLU(),
            nn.Dropout(dropout),
            
            nn.Linear(128, 64),
            nn.BatchNorm1d(64),
            nn.ReLU(),
            nn.Dropout(dropout)
        )
        
        # Direction classification head
        self.direction_classifier = nn.Linear(64, num_classes)
        
        # Price regression head
        self.price_regressor = nn.Linear(64, 1)
        
    def forward(self, x):
        batch_size = x.size(0)
        
        # Reshape from flattened to sequential: (batch, timesteps, features)
        x = x.view(batch_size, self.n_timesteps, self.n_features)
        
        # LSTM layers
        lstm_out1, _ = self.lstm1(x)
        lstm_out2, _ = self.lstm2(lstm_out1)
        
        # Attention mechanism
        attn_out, _ = self.attention(lstm_out2, lstm_out2, lstm_out2)
        
        # Use last timestep output
        final_hidden = attn_out[:, -1, :]  # (batch, hidden_size)
        
        # Shared features
        shared_features = self.shared_head(final_hidden)
        
        # Multi-task outputs
        direction_output = self.direction_classifier(shared_features)
        price_output = self.price_regressor(shared_features)
        
        return direction_output, price_output

def add_technical_indicators(df, price_col='close'):
    print("  üîß Adding technical indicators...")
    
    # Moving averages
    for period in [5, 10, 20, 50]:
        df[f'sma_{period}'] = df[price_col].rolling(window=period).mean()
        df[f'ema_{period}'] = df[price_col].ewm(span=period).mean()
        df[f'price_vs_sma{period}'] = df[price_col] / df[f'sma_{period}']
    
    # Crossovers
    df['sma5_vs_sma10'] = df['sma_5'] / df['sma_10']
    df['sma10_vs_sma20'] = df['sma_10'] / df['sma_20']
    
    # Volatility and momentum
    df['returns'] = df[price_col].pct_change()
    for period in [5, 10, 20]:
        df[f'volatility_{period}'] = df['returns'].rolling(window=period).std()
        df[f'momentum_{period}'] = df[price_col].pct_change(period)
        df[f'roc_{period}'] = df[price_col].pct_change(period) * 100
    
    # Bollinger Bands
    df['bb_middle'] = df[price_col].rolling(window=20).mean()
    bb_std = df[price_col].rolling(window=20).std()
    df['bb_upper'] = df['bb_middle'] + (bb_std * 2)
    df['bb_lower'] = df['bb_middle'] - (bb_std * 2)
    df['bb_position'] = (df[price_col] - df['bb_lower']) / (df['bb_upper'] - df['bb_lower'])
    
    # RSI
    delta = df[price_col].diff()
    gain = (delta.where(delta > 0, 0)).rolling(window=14).mean()
    loss = (-delta.where(delta < 0, 0)).rolling(window=14).mean()
    rs = gain / loss
    df['rsi'] = 100 - (100 / (1 + rs))
    
    return df

def create_labels(df, price_col='close', threshold=0.0001):
    print("  üéØ Creating directional labels...")
    
    future_prices = df[price_col].shift(-1)
    returns = (future_prices - df[price_col]) / df[price_col]
    
    # 3-class classification: DOWN(0), SIDEWAYS(1), UP(2)
    labels = np.where(returns > threshold, 2,
                     np.where(returns < -threshold, 0, 1))
    
    df = df.iloc[:-1].copy()
    df['direction'] = labels[:-1]
    
    unique, counts = np.unique(labels[:-1], return_counts=True)
    total = len(labels[:-1])
    
    print(f"    üìä Label Distribution:")
    names = {0: "DOWN", 1: "SIDEWAYS", 2: "UP"}
    for label, count in zip(unique, counts):
        print(f"      {names[label]}: {count:,} ({count/total*100:.1f}%)")
    
    return df

def create_sequences(data, feature_cols, target_col, n_steps=100):
    """Optimized vectorized sequence creation"""
    print(f"  üì¶ Creating sequences for {target_col}...")
    
    # Convert to numpy for faster operations
    if isinstance(feature_cols, list) and len(feature_cols) > 1:
        feature_data = data[feature_cols].values
    else:
        feature_data = data[feature_cols].values.reshape(-1, 1)
    
    target_data = data[target_col].values
    
    n_samples = len(data) - n_steps
    n_features = feature_data.shape[1]
    
    # Pre-allocate arrays (much faster)
    X = np.zeros((n_samples, n_steps * n_features))
    y = np.zeros(n_samples)
    
    print(f"    Vectorizing {n_samples} sequences...")
    
    # Vectorized sequence creation (much faster than loop)
    for i in range(n_samples):
        start_idx = i
        end_idx = i + n_steps
        sequence = feature_data[start_idx:end_idx].flatten()
        X[i] = sequence
        y[i] = target_data[end_idx]
        
        # Progress every 5000 samples
        if (i + 1) % 5000 == 0:
            print(f"    Progress: {i+1:,}/{n_samples:,} ({(i+1)/n_samples*100:.1f}%)")
    
    print(f"  ‚úÖ Sequences created: {X.shape}")
    return X, y

def train_on_rtx3060(model, train_loader, val_loader, epochs=50, gradient_accumulation_steps=1, 
                    use_lr_finder=True, use_early_stopping=True):
    model = model.to(device)
    
    # Multi-task loss functions
    direction_criterion = nn.CrossEntropyLoss(label_smoothing=0.1)
    price_criterion = nn.MSELoss()
    
    # Initialize optimizer with a placeholder LR (will be updated by LR finder)
    optimizer = optim.AdamW(model.parameters(), lr=0.001, weight_decay=1e-4)
    
    # üîç NEW: Learning Rate Finder
    if use_lr_finder:
        lr_finder = LearningRateFinder(model, optimizer, direction_criterion, device)
        optimal_lr = lr_finder.find_lr(train_loader, num_iter=50)
        
        # Update optimizer with optimal learning rate
        for param_group in optimizer.param_groups:
            param_group['lr'] = optimal_lr
        print(f"üéØ Using optimal learning rate: {optimal_lr:.2e}")
    else:
        optimal_lr = 0.001
        print(f"üìä Using default learning rate: {optimal_lr:.2e}")
    
    # Better learning rate scheduling
    scheduler = optim.lr_scheduler.OneCycleLR(
        optimizer, 
        max_lr=optimal_lr * 3,  # Peak LR is 3x the starting LR
        steps_per_epoch=len(train_loader) // gradient_accumulation_steps, 
        epochs=epochs,
        pct_start=0.3
    )
    
    # üõë NEW: Early Stopping
    early_stopping = EarlyStopping(patience=10, min_delta=0.0001) if use_early_stopping else None
    
    print(f"üöÄ Training on {device} with {epochs} epochs...")
    if use_amp:
        print("‚ö° Using Automatic Mixed Precision for 2x speed boost!")
    if gradient_accumulation_steps > 1:
        print(f"üìà Using Gradient Accumulation: {gradient_accumulation_steps} steps (effective batch size: {train_loader.batch_size * gradient_accumulation_steps})")
    if use_early_stopping:
        print("üõë Early Stopping enabled (patience=10)")
    
    training_stats = {
        'train_losses': [],
        'val_losses': [],
        'learning_rates': [],
        'epochs_completed': 0,
        'early_stopped': False
    }
    
    with tqdm(total=epochs, desc="üéÆ RTX 3060 Training", unit="epoch") as pbar:
        for epoch in range(epochs):
            model.train()
            train_loss = 0
            optimizer.zero_grad()  # Zero gradients at the start of epoch
            
            # Training loop with gradient accumulation
            for batch_idx, (X_batch, y_direction_batch, y_price_batch) in enumerate(train_loader):
                X_batch = X_batch.to(device, non_blocking=True)
                y_direction_batch = y_direction_batch.to(device, non_blocking=True)
                y_price_batch = y_price_batch.to(device, non_blocking=True)
                
                if use_amp:
                    with autocast():
                        direction_outputs, price_outputs, dir_unc, price_unc = model(X_batch)
                        direction_loss = direction_criterion(direction_outputs, y_direction_batch)
                        price_loss = price_criterion(price_outputs.squeeze(), y_price_batch)
                        # Weighted combination of losses
                        total_loss = direction_loss + 0.1 * price_loss
                        # Scale loss for gradient accumulation
                        total_loss = total_loss / gradient_accumulation_steps
                    
                    scaler.scale(total_loss).backward()
                    
                    # üìà NEW: Gradient Accumulation with clipping
                    if (batch_idx + 1) % gradient_accumulation_steps == 0:
                        # Gradient clipping for stability
                        scaler.unscale_(optimizer)
                        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
                        scaler.step(optimizer)
                        scaler.update()
                        optimizer.zero_grad()
                        scheduler.step()  # Step scheduler after accumulated gradients
                else:
                    direction_outputs, price_outputs, dir_unc, price_unc = model(X_batch)
                    direction_loss = direction_criterion(direction_outputs, y_direction_batch)
                    price_loss = price_criterion(price_outputs.squeeze(), y_price_batch)
                    total_loss = direction_loss + 0.1 * price_loss
                    total_loss = total_loss / gradient_accumulation_steps
                    
                    total_loss.backward()
                    
                    # üìà NEW: Gradient Accumulation with clipping
                    if (batch_idx + 1) % gradient_accumulation_steps == 0:
                        # Gradient clipping for stability
                        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
                        optimizer.step()
                        optimizer.zero_grad()
                        scheduler.step()  # Step scheduler after accumulated gradients
                
                train_loss += total_loss.item() * gradient_accumulation_steps
            
            # Validation
            model.eval()
            val_loss = 0
            with torch.no_grad():
                for X_batch, y_direction_batch, y_price_batch in val_loader:
                    X_batch = X_batch.to(device, non_blocking=True)
                    y_direction_batch = y_direction_batch.to(device, non_blocking=True)
                    y_price_batch = y_price_batch.to(device, non_blocking=True)
                    
                    if use_amp:
                        with autocast():
                            direction_outputs, price_outputs, dir_unc, price_unc = model(X_batch)
                            direction_loss = direction_criterion(direction_outputs, y_direction_batch)
                            price_loss = price_criterion(price_outputs.squeeze(), y_price_batch)
                            total_loss = direction_loss + 0.1 * price_loss
                    else:
                        direction_outputs, price_outputs, dir_unc, price_unc = model(X_batch)
                        direction_loss = direction_criterion(direction_outputs, y_direction_batch)
                        price_loss = price_criterion(price_outputs.squeeze(), y_price_batch)
                        total_loss = direction_loss + 0.1 * price_loss
                    val_loss += total_loss.item()
            
            avg_train_loss = train_loss / len(train_loader)
            avg_val_loss = val_loss / len(val_loader)
            current_lr = optimizer.param_groups[0]['lr']
            
            # Store training statistics
            training_stats['train_losses'].append(avg_train_loss)
            training_stats['val_losses'].append(avg_val_loss)
            training_stats['learning_rates'].append(current_lr)
            training_stats['epochs_completed'] = epoch + 1
            
            pbar.set_postfix({
                'train_loss': f'{avg_train_loss:.4f}',
                'val_loss': f'{avg_val_loss:.4f}',
                'lr': f'{current_lr:.1e}',
                'patience': f'{early_stopping.counter if early_stopping else "N/A"}'
            })
            pbar.update(1)
            
            # Memory cleanup after each epoch
            if torch.cuda.is_available():
                torch.cuda.empty_cache()
            
            # üõë NEW: Early Stopping Check
            if early_stopping and early_stopping(avg_val_loss, model):
                print(f"\nüõë Early stopping triggered at epoch {epoch + 1}")
                print(f"   Best validation loss: {early_stopping.best_loss:.6f}")
                print(f"   Current validation loss: {avg_val_loss:.6f}")
                training_stats['early_stopped'] = True
                break
    
    return training_stats

def compile_model_for_inference(model, sample_input):
    """üöÄ NEW: Compile model with TorchScript for faster inference"""
    print("üîß Compiling model with TorchScript for faster inference...")
    
    try:
        model.eval()
        with torch.no_grad():
            # Trace the model
            traced_model = torch.jit.trace(model, sample_input)
            
            # Optimize for inference
            traced_model = torch.jit.optimize_for_inference(traced_model)
            
            print("‚úÖ Model successfully compiled with TorchScript!")
            return traced_model
    except Exception as e:
        print(f"‚ö†Ô∏è TorchScript compilation failed: {e}")
        print("   Falling back to regular PyTorch model")
        return model

# ========== MEDIUM IMPACT OPTIMIZATION CLASSES ==========

class FocalLoss(nn.Module):
    """Advanced Focal Loss for imbalanced classification"""
    def __init__(self, alpha=1, gamma=2, reduction='mean'):
        super(FocalLoss, self).__init__()
        self.alpha = alpha
        self.gamma = gamma
        self.reduction = reduction
        
    def forward(self, inputs, targets):
        ce_loss = F.cross_entropy(inputs, targets, reduction='none')
        pt = torch.exp(-ce_loss)
        focal_loss = self.alpha * (1 - pt) ** self.gamma * ce_loss
        
        if self.reduction == 'mean':
            return focal_loss.mean()
        elif self.reduction == 'sum':
            return focal_loss.sum()
        else:
            return focal_loss

class TimeSeriesAugmentation:
    """Advanced time series data augmentation"""
    def __init__(self, noise_factor=0.005, scaling_factor=0.1, time_shift_ratio=0.1):
        self.noise_factor = noise_factor
        self.scaling_factor = scaling_factor
        self.time_shift_ratio = time_shift_ratio
        
    def add_noise(self, data):
        """Add Gaussian noise"""
        noise = torch.randn_like(data) * self.noise_factor
        return data + noise
    
    def scale(self, data):
        """Random scaling"""
        scale = 1 + (torch.rand(1).item() - 0.5) * 2 * self.scaling_factor
        return data * scale
    
    def time_shift(self, data):
        """Random time shifting within sequence"""
        seq_len = data.shape[1]
        shift = int(seq_len * self.time_shift_ratio * (torch.rand(1).item() - 0.5))
        if shift != 0:
            if shift > 0:
                data = torch.cat([data[:, shift:], data[:, :shift]], dim=1)
            else:
                data = torch.cat([data[:, shift:], data[:, :shift]], dim=1)
        return data
    
    def augment(self, data, probability=0.5):
        """Apply random augmentations"""
        if torch.rand(1).item() < probability:
            aug_type = torch.randint(0, 3, (1,)).item()
            if aug_type == 0:
                return self.add_noise(data)
            elif aug_type == 1:
                return self.scale(data)
            else:
                return self.time_shift(data)
        return data

class ChannelAttention(nn.Module):
    """Memory-efficient channel attention for feature importance"""
    def __init__(self, num_channels, reduction=16):
        super(ChannelAttention, self).__init__()
        self.reduction = reduction
        reduced_channels = max(1, num_channels // reduction)
        
        self.fc = nn.Sequential(
            nn.Linear(num_channels, reduced_channels, bias=False),
            nn.ReLU(),
            nn.Linear(reduced_channels, num_channels, bias=False)
        )
        self.sigmoid = nn.Sigmoid()
        
    def forward(self, x):
        # x shape: (batch, seq_len, channels)
        b, s, c = x.shape
        
        # Memory-efficient global pooling
        # Average pooling across sequence dimension
        avg_pooled = x.mean(dim=1)  # (batch, channels)
        
        # Generate attention weights
        attention_weights = self.sigmoid(self.fc(avg_pooled))  # (batch, channels)
        
        # Apply attention weights
        attention_weights = attention_weights.unsqueeze(1)  # (batch, 1, channels)
        return x * attention_weights

class TransformerBlock(nn.Module):
    """Advanced Transformer block with residual connections"""
    def __init__(self, d_model, nhead, dim_feedforward=512, dropout=0.1):
        super(TransformerBlock, self).__init__()
        self.self_attn = nn.MultiheadAttention(d_model, nhead, dropout=dropout, batch_first=True)
        self.linear1 = nn.Linear(d_model, dim_feedforward)
        self.dropout = nn.Dropout(dropout)
        self.linear2 = nn.Linear(dim_feedforward, d_model)
        
        self.norm1 = nn.LayerNorm(d_model)
        self.norm2 = nn.LayerNorm(d_model)
        self.dropout1 = nn.Dropout(dropout)
        self.dropout2 = nn.Dropout(dropout)
        self.activation = nn.GELU()  # Better than ReLU for transformers
        
    def forward(self, src):
        # Self-attention with residual connection
        src2 = self.norm1(src)
        attn_output, _ = self.self_attn(src2, src2, src2)
        src = src + self.dropout1(attn_output)
        
        # Feedforward with residual connection
        src2 = self.norm2(src)
        src2 = self.linear2(self.dropout(self.activation(self.linear1(src2))))
        src = src + self.dropout2(src2)
        
        return src

class RTX3060SimpleForexNet(nn.Module):
    """Simplified, more stable network for RTX 3060"""
    def __init__(self, input_size, n_timesteps=100, num_classes=3, dropout=0.2):
        super(RTX3060SimpleForexNet, self).__init__()
        
        # Calculate feature dimension
        self.n_features = input_size // n_timesteps
        self.n_timesteps = n_timesteps
        
        # Simple input normalization
        self.input_norm = nn.BatchNorm1d(input_size)
        
        # Bidirectional LSTM layers (proven architecture)
        self.lstm1 = nn.LSTM(
            input_size=self.n_features,
            hidden_size=64,
            num_layers=2,
            batch_first=True,
            dropout=dropout,
            bidirectional=True
        )
        
        self.lstm2 = nn.LSTM(
            input_size=128,  # bidirectional = 64*2
            hidden_size=32,
            num_layers=1,
            batch_first=True,
            dropout=dropout,
            bidirectional=True
        )
        
        # Simple attention (much more stable than multi-head)
        self.attention_weights = nn.Linear(64, 1)  # 32*2 = 64
        
        # Feature extractor
        self.feature_extractor = nn.Sequential(
            nn.Linear(64, 128),
            nn.BatchNorm1d(128),
            nn.ReLU(),
            nn.Dropout(dropout),
            
            nn.Linear(128, 64),
            nn.BatchNorm1d(64),
            nn.ReLU(),
            nn.Dropout(dropout),
            
            nn.Linear(64, 32),
            nn.BatchNorm1d(32),
            nn.ReLU(),
        )
        
        # Multi-task heads
        self.direction_classifier = nn.Sequential(
            nn.Linear(32, 16),
            nn.ReLU(),
            nn.Dropout(dropout),
            nn.Linear(16, num_classes)
        )
        
        self.price_regressor = nn.Sequential(
            nn.Linear(32, 16),
            nn.ReLU(),
            nn.Dropout(dropout),
            nn.Linear(16, 1)
        )
        
        # Simple uncertainty estimation
        self.direction_uncertainty = nn.Sequential(
            nn.Linear(32, 8),
            nn.ReLU(),
            nn.Linear(8, 1),
            nn.Softplus()
        )
        
        self.price_uncertainty = nn.Sequential(
            nn.Linear(32, 8),
            nn.ReLU(),
            nn.Linear(8, 1),
            nn.Softplus()
        )
        
    def forward(self, x):
        batch_size = x.size(0)
        
        # Input normalization for stability
        x_norm = self.input_norm(x)
        
        # Reshape to sequential format
        x = x_norm.view(batch_size, self.n_timesteps, self.n_features)
        
        # LSTM processing
        lstm_out1, _ = self.lstm1(x)
        lstm_out2, _ = self.lstm2(lstm_out1)
        
        # Simple attention pooling (much more stable)
        attention_scores = torch.softmax(self.attention_weights(lstm_out2).squeeze(-1), dim=1)
        attended = torch.bmm(attention_scores.unsqueeze(1), lstm_out2).squeeze(1)
        
        # Feature extraction
        features = self.feature_extractor(attended)
        
        # Multi-task outputs
        direction_output = self.direction_classifier(features)
        price_output = self.price_regressor(features)
        direction_uncertainty = self.direction_uncertainty(features)
        price_uncertainty = self.price_uncertainty(features)
        
        return direction_output, price_output, direction_uncertainty, price_uncertainty

class ModelEnsemble:
    """Ensemble multiple models for better performance"""
    def __init__(self, models: List[nn.Module]):
        self.models = models
        self.num_models = len(models)
        
    def predict(self, x):
        """Ensemble prediction with uncertainty"""
        direction_preds = []
        price_preds = []
        direction_uncertainties = []
        price_uncertainties = []
        
        for model in self.models:
            model.eval()
            with torch.no_grad():
                # Ensure input is on the same device as the model
                model_device = next(model.parameters()).device
                x_device = x.to(model_device)
                
                dir_out, price_out, dir_unc, price_unc = model(x_device)
                
                direction_preds.append(F.softmax(dir_out, dim=1))
                price_preds.append(price_out)
                direction_uncertainties.append(dir_unc)
                price_uncertainties.append(price_unc)
        
        # Average predictions
        avg_direction = torch.stack(direction_preds).mean(dim=0)
        avg_price = torch.stack(price_preds).mean(dim=0)
        avg_dir_uncertainty = torch.stack(direction_uncertainties).mean(dim=0)
        avg_price_uncertainty = torch.stack(price_uncertainties).mean(dim=0)
        
        # Add ensemble uncertainty (variance across models)
        dir_variance = torch.stack(direction_preds).var(dim=0).mean(dim=1, keepdim=True)
        price_variance = torch.stack(price_preds).var(dim=0)
        
        total_dir_uncertainty = avg_dir_uncertainty + dir_variance
        total_price_uncertainty = avg_price_uncertainty + price_variance
        
        return avg_direction, avg_price, total_dir_uncertainty, total_price_uncertainty

def add_advanced_technical_indicators(df, price_col='close'):
    """üîß Enhanced technical indicators with multi-timeframe analysis"""
    print("  üîß Adding advanced multi-timeframe features...")
    
    # Original indicators (keeping existing ones)
    for period in [5, 10, 20, 50]:
        df[f'sma_{period}'] = df[price_col].rolling(window=period).mean()
        df[f'ema_{period}'] = df[price_col].ewm(span=period).mean()
        df[f'price_vs_sma{period}'] = df[price_col] / df[f'sma_{period}']
    
    # Advanced moving averages
    df['wma_10'] = df[price_col].rolling(window=10).apply(lambda x: (x * np.arange(1, len(x) + 1)).sum() / np.arange(1, len(x) + 1).sum())
    df['hull_ma_14'] = df[price_col].ewm(span=int(14/2)).mean() * 2 - df[price_col].ewm(span=14).mean()
    
    # Crossovers and divergences
    df['sma5_vs_sma10'] = df['sma_5'] / df['sma_10']
    df['sma10_vs_sma20'] = df['sma_10'] / df['sma_20']
    df['ema5_vs_ema20'] = df['ema_5'] / df['ema_20']
    
    # Advanced volatility indicators
    df['returns'] = df[price_col].pct_change()
    for period in [5, 10, 20, 50]:
        df[f'volatility_{period}'] = df['returns'].rolling(window=period).std()
        df[f'momentum_{period}'] = df[price_col].pct_change(period)
        df[f'roc_{period}'] = df[price_col].pct_change(period) * 100
        
        # Advanced volatility metrics
        df[f'realized_vol_{period}'] = df['returns'].rolling(window=period).std() * np.sqrt(period)
        df[f'vol_of_vol_{period}'] = df[f'volatility_{period}'].rolling(window=period).std()
    
    # Bollinger Bands with advanced features
    df['bb_middle'] = df[price_col].rolling(window=20).mean()
    bb_std = df[price_col].rolling(window=20).std()
    df['bb_upper'] = df['bb_middle'] + (bb_std * 2)
    df['bb_lower'] = df['bb_middle'] - (bb_std * 2)
    df['bb_position'] = (df[price_col] - df['bb_lower']) / (df['bb_upper'] - df['bb_lower'])
    df['bb_width'] = (df['bb_upper'] - df['bb_lower']) / df['bb_middle']
    df['bb_squeeze'] = df['bb_width'] < df['bb_width'].rolling(window=20).quantile(0.2)
    
    # Advanced RSI variants
    delta = df[price_col].diff()
    gain = (delta.where(delta > 0, 0)).rolling(window=14).mean()
    loss = (-delta.where(delta < 0, 0)).rolling(window=14).mean()
    rs = gain / loss
    df['rsi'] = 100 - (100 / (1 + rs))
    df['rsi_divergence'] = df['rsi'].diff()
    df['rsi_overbought'] = df['rsi'] > 70
    df['rsi_oversold'] = df['rsi'] < 30
    
    # Stochastic oscillators
    high_14 = df[price_col].rolling(window=14).max()
    low_14 = df[price_col].rolling(window=14).min()
    df['stoch_k'] = 100 * (df[price_col] - low_14) / (high_14 - low_14)
    df['stoch_d'] = df['stoch_k'].rolling(window=3).mean()
    
    # MACD with signal line
    exp1 = df[price_col].ewm(span=12).mean()
    exp2 = df[price_col].ewm(span=26).mean()
    df['macd'] = exp1 - exp2
    df['macd_signal'] = df['macd'].ewm(span=9).mean()
    df['macd_histogram'] = df['macd'] - df['macd_signal']
    
    # Williams %R
    df['williams_r'] = -100 * (high_14 - df[price_col]) / (high_14 - low_14)
    
    # Average True Range (ATR)
    high_low = high_14 - low_14
    high_close = np.abs(high_14 - df[price_col].shift())
    low_close = np.abs(low_14 - df[price_col].shift())
    ranges = pd.concat([high_low, high_close, low_close], axis=1)
    true_range = ranges.max(axis=1)
    df['atr'] = true_range.rolling(window=14).mean()
    df['atr_percent'] = df['atr'] / df[price_col] * 100
    
    # Fibonacci retracements (dynamic)
    df['price_max_20'] = df[price_col].rolling(window=20).max()
    df['price_min_20'] = df[price_col].rolling(window=20).min()
    price_range = df['price_max_20'] - df['price_min_20']
    df['fib_23.6'] = df['price_max_20'] - 0.236 * price_range
    df['fib_38.2'] = df['price_max_20'] - 0.382 * price_range
    df['fib_61.8'] = df['price_max_20'] - 0.618 * price_range
    
    # Market structure indicators
    df['higher_high'] = (df[price_col] > df[price_col].shift(1)) & (df[price_col].shift(1) > df[price_col].shift(2))
    df['lower_low'] = (df[price_col] < df[price_col].shift(1)) & (df[price_col].shift(1) < df[price_col].shift(2))
    df['trend_strength'] = df['higher_high'].rolling(window=10).sum() - df['lower_low'].rolling(window=10).sum()
    
    print(f"    ‚úÖ Added {len([col for col in df.columns if col not in [price_col]])} technical indicators")
    return df

class AdvancedForexDataset(Dataset):
    """Enhanced dataset with data augmentation"""
    def __init__(self, X, y_direction, y_price, augmentation=None, training=True):
        self.X = torch.FloatTensor(X)
        self.y_direction = torch.LongTensor(y_direction)
        self.y_price = torch.FloatTensor(y_price)
        self.augmentation = augmentation
        self.training = training
        
    def __len__(self):
        return len(self.X)
    
    def __getitem__(self, idx):
        x = self.X[idx]
        
        # Apply augmentation during training
        if self.training and self.augmentation is not None:
            # Reshape for augmentation (add sequence dimension)
            x_reshaped = x.view(1, -1)  # (1, features)
            x_augmented = self.augmentation.augment(x_reshaped)
            x = x_augmented.squeeze(0)
        
        return x, self.y_direction[idx], self.y_price[idx]

def quantize_model(model, sample_input):
    """üöÄ Quantize model for faster inference"""
    print("‚ö° Quantizing model for 4x faster inference...")
    
    try:
        # Prepare model for quantization
        model.eval()
        model_quantized = torch.quantization.quantize_dynamic(
            model, 
            {nn.Linear, nn.LSTM, nn.MultiheadAttention}, 
            dtype=torch.qint8
        )
        
        print("‚úÖ Model successfully quantized to INT8!")
        return model_quantized
    except Exception as e:
        print(f"‚ö†Ô∏è Quantization failed: {e}")
        print("   Falling back to FP32 model")
        return model

def export_to_onnx(model, sample_input, output_path):
    """üîÑ Export model to ONNX for MetaTrader integration"""
    print("üîÑ Exporting model to ONNX format...")
    
    try:
        model.eval()
        
        # Create sample input
        dummy_input = sample_input.cpu()
        
        # Export with dynamic batch size
        torch.onnx.export(
            model.cpu(),
            dummy_input,
            output_path,
            input_names=['input'],
            output_names=['direction_output', 'price_output', 'direction_uncertainty', 'price_uncertainty'],
            dynamic_axes={
                'input': {0: 'batch_size'},
                'direction_output': {0: 'batch_size'},
                'price_output': {0: 'batch_size'},
                'direction_uncertainty': {0: 'batch_size'},
                'price_uncertainty': {0: 'batch_size'}
            },
            opset_version=13
        )
        
        # Verify ONNX model
        onnx_model = onnx.load(output_path)
        onnx.checker.check_model(onnx_model)
        
        print(f"‚úÖ ONNX model exported: {output_path}")
        return True
    except Exception as e:
        print(f"‚ö†Ô∏è ONNX export failed: {e}")
        return False

def train_advanced_ensemble(models, train_loader, val_loader, epochs=50, 
                          gradient_accumulation_steps=1, use_lr_finder=True, 
                          use_early_stopping=True, use_focal_loss=True):
    """üéØ Train ensemble of advanced models"""
    
    print(f"üöÄ Training ensemble of {len(models)} advanced models...")
    
    # Use Focal Loss for better imbalanced classification
    if use_focal_loss:
        direction_criterion = FocalLoss(alpha=1, gamma=2)
        print("üéØ Using Focal Loss for imbalanced classification")
    else:
        direction_criterion = nn.CrossEntropyLoss(label_smoothing=0.1)
    
    price_criterion = nn.MSELoss()
    uncertainty_criterion = nn.MSELoss()  # For uncertainty calibration
    
    # Train each model in the ensemble
    ensemble_stats = []
    
    for i, model in enumerate(models):
        print(f"\nüî• Training Model {i+1}/{len(models)}...")
        model = model.to(device)
        
        # Initialize optimizer
        optimizer = optim.AdamW(model.parameters(), lr=0.001, weight_decay=1e-4)
        
        # Learning Rate Finder
        if use_lr_finder:
            lr_finder = LearningRateFinder(model, optimizer, direction_criterion, device)
            optimal_lr = lr_finder.find_lr(train_loader, num_iter=30)
            
            for param_group in optimizer.param_groups:
                param_group['lr'] = optimal_lr
            print(f"üéØ Model {i+1} optimal LR: {optimal_lr:.2e}")
        
        # Advanced scheduling
        scheduler = optim.lr_scheduler.OneCycleLR(
            optimizer, 
            max_lr=optimal_lr * 3 if use_lr_finder else 0.003,
            steps_per_epoch=len(train_loader) // gradient_accumulation_steps, 
            epochs=epochs,
            pct_start=0.3
        )
        
        # Early stopping
        early_stopping = EarlyStopping(patience=8, min_delta=0.0001) if use_early_stopping else None
        
        # Training statistics
        model_stats = {
            'train_losses': [],
            'val_losses': [],
            'learning_rates': [],
            'epochs_completed': 0,
            'early_stopped': False
        }
        
        # Training loop
        with tqdm(total=epochs, desc=f"üéÆ Model {i+1} Training", unit="epoch") as pbar:
            for epoch in range(epochs):
                model.train()
                train_loss = 0
                optimizer.zero_grad()
                
                for batch_idx, (X_batch, y_direction_batch, y_price_batch) in enumerate(train_loader):
                    X_batch = X_batch.to(device, non_blocking=True)
                    y_direction_batch = y_direction_batch.to(device, non_blocking=True)
                    y_price_batch = y_price_batch.to(device, non_blocking=True)
                    
                    if use_amp:
                        with autocast():
                            direction_outputs, price_outputs, dir_unc, price_unc = model(X_batch)
                            
                            # Multi-task loss with uncertainty
                            direction_loss = direction_criterion(direction_outputs, y_direction_batch)
                            price_loss = price_criterion(price_outputs.squeeze(), y_price_batch)
                            
                            # Uncertainty loss (encourage calibrated uncertainty)
                            uncertainty_loss = 0.01 * (dir_unc.mean() + price_unc.mean())
                            
                            total_loss = direction_loss + 0.1 * price_loss + uncertainty_loss
                            total_loss = total_loss / gradient_accumulation_steps
                        
                        scaler.scale(total_loss).backward()
                        
                        if (batch_idx + 1) % gradient_accumulation_steps == 0:
                            scaler.step(optimizer)
                            scaler.update()
                            optimizer.zero_grad()
                            scheduler.step()
                    else:
                        direction_outputs, price_outputs, dir_unc, price_unc = model(X_batch)
                        direction_loss = direction_criterion(direction_outputs, y_direction_batch)
                        price_loss = price_criterion(price_outputs.squeeze(), y_price_batch)
                        uncertainty_loss = 0.01 * (dir_unc.mean() + price_unc.mean())
                        total_loss = direction_loss + 0.1 * price_loss + uncertainty_loss
                        total_loss = total_loss / gradient_accumulation_steps
                        
                        total_loss.backward()
                        
                        if (batch_idx + 1) % gradient_accumulation_steps == 0:
                            optimizer.step()
                            optimizer.zero_grad()
                            scheduler.step()
                    
                    train_loss += total_loss.item() * gradient_accumulation_steps
                
                # Validation
                model.eval()
                val_loss = 0
                with torch.no_grad():
                    for X_batch, y_direction_batch, y_price_batch in val_loader:
                        X_batch = X_batch.to(device, non_blocking=True)
                        y_direction_batch = y_direction_batch.to(device, non_blocking=True)
                        y_price_batch = y_price_batch.to(device, non_blocking=True)
                        
                        direction_outputs, price_outputs, dir_unc, price_unc = model(X_batch)
                        direction_loss = direction_criterion(direction_outputs, y_direction_batch)
                        price_loss = price_criterion(price_outputs.squeeze(), y_price_batch)
                        uncertainty_loss = 0.01 * (dir_unc.mean() + price_unc.mean())
                        total_loss = direction_loss + 0.1 * price_loss + uncertainty_loss
                        val_loss += total_loss.item()
                
                avg_train_loss = train_loss / len(train_loader)
                avg_val_loss = val_loss / len(val_loader)
                current_lr = optimizer.param_groups[0]['lr']
                
                # Check for NaN losses and stop training if detected
                if math.isnan(avg_train_loss) or math.isnan(avg_val_loss):
                    print(f"\n‚ö†Ô∏è Model {i+1} NaN detected at epoch {epoch + 1} - stopping training")
                    print(f"   Train loss: {avg_train_loss}, Val loss: {avg_val_loss}")
                    model_stats['early_stopped'] = True
                    break
                
                model_stats['train_losses'].append(avg_train_loss)
                model_stats['val_losses'].append(avg_val_loss)
                model_stats['learning_rates'].append(current_lr)
                model_stats['epochs_completed'] = epoch + 1
                
                pbar.set_postfix({
                    'train_loss': f'{avg_train_loss:.4f}',
                    'val_loss': f'{avg_val_loss:.4f}',
                    'lr': f'{current_lr:.1e}'
                })
                pbar.update(1)
                
                # Early stopping
                if early_stopping and early_stopping(avg_val_loss, model):
                    print(f"\nüõë Model {i+1} stopped early at epoch {epoch + 1}")
                    model_stats['early_stopped'] = True
                    break
        
        ensemble_stats.append(model_stats)
    
    print(f"‚úÖ Ensemble training completed!")
    return ensemble_stats

# Advanced Transformer Components for High Accuracy
class AdvancedPositionalEncoding(nn.Module):
    """Advanced positional encoding with learnable components"""
    def __init__(self, d_model, max_len=1000, dropout=0.1):
        super(AdvancedPositionalEncoding, self).__init__()
        self.dropout = nn.Dropout(p=dropout)
        
        # Standard sinusoidal encoding
        pe = torch.zeros(max_len, d_model)
        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)
        div_term = torch.exp(torch.arange(0, d_model, 2).float() * 
                           (-math.log(10000.0) / d_model))
        pe[:, 0::2] = torch.sin(position * div_term)
        pe[:, 1::2] = torch.cos(position * div_term)
        
        self.register_buffer('pe', pe.unsqueeze(0))
        
        # Learnable position embeddings for fine-tuning
        self.learnable_pe = nn.Parameter(torch.randn(1, max_len, d_model) * 0.1)
        
    def forward(self, x):
        seq_len = x.size(1)
        # Combine fixed and learnable positional encodings
        pos_encoding = self.pe[:, :seq_len] + self.learnable_pe[:, :seq_len]
        x = x + pos_encoding
        return self.dropout(x)

class MultiScaleAttention(nn.Module):
    """Multi-scale attention for different time horizons"""
    def __init__(self, d_model, num_heads, scales=[1, 2, 4], dropout=0.1):
        super(MultiScaleAttention, self).__init__()
        self.scales = scales
        self.attentions = nn.ModuleList([
            nn.MultiheadAttention(d_model, num_heads, dropout=dropout, batch_first=True)
            for _ in scales
        ])
        self.scale_weights = nn.Parameter(torch.ones(len(scales)) / len(scales))
        self.norm = nn.LayerNorm(d_model)
        
    def forward(self, x):
        # x shape: (batch, seq_len, d_model)
        outputs = []
        
        for i, (scale, attention) in enumerate(zip(self.scales, self.attentions)):
            if scale == 1:
                # Full resolution
                attn_out, _ = attention(x, x, x)
            else:
                # Downsampled attention
                seq_len = x.size(1)
                if seq_len >= scale:
                    # Average pooling for downsampling
                    x_down = F.avg_pool1d(x.transpose(1, 2), kernel_size=scale, stride=scale).transpose(1, 2)
                    attn_out, _ = attention(x_down, x_down, x_down)
                    # Upsample back to original size
                    attn_out = F.interpolate(attn_out.transpose(1, 2), size=seq_len, mode='linear', align_corners=False).transpose(1, 2)
                else:
                    attn_out, _ = attention(x, x, x)
            
            outputs.append(attn_out * self.scale_weights[i])
        
        # Weighted combination of multi-scale outputs
        combined = sum(outputs)
        return self.norm(combined + x)  # Residual connection

class AdvancedTransformerBlock(nn.Module):
    """Advanced Transformer block with enhanced components"""
    def __init__(self, d_model, nhead, dim_feedforward=512, dropout=0.1):
        super(AdvancedTransformerBlock, self).__init__()
        
        # Multi-scale attention instead of standard attention
        self.multi_scale_attn = MultiScaleAttention(d_model, nhead, dropout=dropout)
        
        # Enhanced feedforward (simplified for stability)
        self.ff = nn.Sequential(
            nn.Linear(d_model, dim_feedforward),
            nn.GELU(),  # Better than ReLU for transformers
            nn.Dropout(dropout),
            nn.Linear(dim_feedforward, d_model),
        )
        
        self.norm1 = nn.LayerNorm(d_model)
        self.norm2 = nn.LayerNorm(d_model)
        self.dropout1 = nn.Dropout(dropout)
        self.dropout2 = nn.Dropout(dropout)
        
    def forward(self, src):
        # Multi-scale attention with pre-normalization (more stable)
        src2 = self.norm1(src)
        src = src + self.dropout1(self.multi_scale_attn(src2))
        
        # Enhanced feedforward
        src2 = self.norm2(src)
        src = src + self.dropout2(self.ff(src2))
        
        return src

class HighAccuracyTransformerNet(nn.Module):
    """High-accuracy Transformer network with advanced components"""
    def __init__(self, input_size, n_timesteps=100, num_classes=3, dropout=0.15):
        super(HighAccuracyTransformerNet, self).__init__()
        
        self.n_features = input_size // n_timesteps
        self.n_timesteps = n_timesteps
        self.d_model = 128  # Balanced size for RTX 3060
        
        # Advanced input processing
        self.input_projection = nn.Sequential(
            nn.Linear(self.n_features, self.d_model // 2),
            nn.LayerNorm(self.d_model // 2),
            nn.GELU(),
            nn.Dropout(dropout),
            nn.Linear(self.d_model // 2, self.d_model)
        )
        
        # Advanced positional encoding
        self.pos_encoding = AdvancedPositionalEncoding(self.d_model, n_timesteps, dropout)
        
        # Multiple advanced transformer layers (reduced for stability)
        self.transformer_layers = nn.ModuleList([
            AdvancedTransformerBlock(self.d_model, nhead=8, dim_feedforward=512, dropout=dropout)
            for _ in range(4)  # Balanced depth for RTX 3060
        ])
        
        # Hierarchical pooling (multi-resolution)
        self.global_pool = nn.AdaptiveAvgPool1d(1)
        self.max_pool = nn.AdaptiveMaxPool1d(1)
        
        # Advanced feature extraction
        self.feature_extractor = nn.Sequential(
            nn.Linear(self.d_model * 2, 256),  # Concat avg+max pooling
            nn.LayerNorm(256),
            nn.GELU(),
            nn.Dropout(dropout),
            
            nn.Linear(256, 128),
            nn.LayerNorm(128),
            nn.GELU(),
            nn.Dropout(dropout),
            
            nn.Linear(128, 64),
            nn.LayerNorm(64),
            nn.GELU(),
        )
        
        # Sophisticated multi-task heads
        self.direction_classifier = nn.Sequential(
            nn.Linear(64, 32),
            nn.LayerNorm(32),
            nn.GELU(),
            nn.Dropout(dropout),
            nn.Linear(32, 16),
            nn.GELU(),
            nn.Linear(16, num_classes)
        )
        
        self.price_regressor = nn.Sequential(
            nn.Linear(64, 32),
            nn.LayerNorm(32),
            nn.GELU(),
            nn.Dropout(dropout),
            nn.Linear(32, 16),
            nn.GELU(),
            nn.Linear(16, 1)
        )
        
        # Enhanced uncertainty estimation
        self.direction_uncertainty = nn.Sequential(
            nn.Linear(64, 16),
            nn.GELU(),
            nn.Linear(16, 8),
            nn.GELU(),
            nn.Linear(8, 1),
            nn.Softplus()
        )
        
        self.price_uncertainty = nn.Sequential(
            nn.Linear(64, 16),
            nn.GELU(),
            nn.Linear(16, 8),
            nn.GELU(),
            nn.Linear(8, 1),
            nn.Softplus()
        )
        
    def forward(self, x):
        batch_size = x.size(0)
        
        # Reshape and project input
        x = x.view(batch_size, self.n_timesteps, self.n_features)
        x = self.input_projection(x)
        
        # Add advanced positional encoding
        x = self.pos_encoding(x)
        
        # Process through advanced transformer layers
        for transformer_layer in self.transformer_layers:
            if self.training:
                # Use gradient checkpointing for memory efficiency
                x = checkpoint(transformer_layer, x, use_reentrant=False)
            else:
                x = transformer_layer(x)
        
        # Hierarchical pooling for better representation
        x_t = x.transpose(1, 2)  # (batch, d_model, seq_len)
        avg_pooled = self.global_pool(x_t).squeeze(-1)  # (batch, d_model)
        max_pooled = self.max_pool(x_t).squeeze(-1)     # (batch, d_model)
        
        # Combine different pooling strategies
        combined = torch.cat([avg_pooled, max_pooled], dim=1)  # (batch, d_model*2)
        
        # Advanced feature extraction
        features = self.feature_extractor(combined)
        
        # Multi-task outputs
        direction_output = self.direction_classifier(features)
        price_output = self.price_regressor(features)
        direction_uncertainty = self.direction_uncertainty(features)
        price_uncertainty = self.price_uncertainty(features)
        
        return direction_output, price_output, direction_uncertainty, price_uncertainty

def main():
    # Load data
    csv_file = 'EURUSDm_H1_201801020600_202412310000.csv'
    print(f"üöÄ Loading EURUSD data for RTX 3060 training...")

    try:
        if os.path.exists(csv_file):
            df = pd.read_csv(csv_file, sep='\t')
            
            if '<DATE>' in df.columns and '<TIME>' in df.columns and '<CLOSE>' in df.columns:
                print("‚úÖ MetaTrader format detected")
                
                df['datetime'] = df['<DATE>'] + ' ' + df['<TIME>']
                data = pd.DataFrame()
                data['time'] = df['datetime']
                data['close'] = df['<CLOSE>']
                data['time'] = pd.to_datetime(data['time'], format='%Y.%m.%d %H:%M:%S')
                data = data.set_index('time')
                data['close'] = pd.to_numeric(data['close'], errors='coerce')
                data = data.dropna()
                
                print(f"‚úÖ Loaded {len(data)} records")
            else:
                raise ValueError("Unrecognized CSV format")
                
    except Exception as e:
        print(f"‚ùå Error: {str(e)}")
        exit(1)

    # Feature engineering
    print("\nüîß Step 1/5: Advanced multi-timeframe feature engineering...")
    data = add_advanced_multi_timeframe_features(data, 'close')

    # Create labels
    print("\nüéØ Step 2/5: Creating labels...")
    data_with_labels = create_labels(data.copy(), 'close', threshold=0.0001)
    data_with_labels = data_with_labels.dropna()

    print(f"‚úÖ Final dataset: {len(data_with_labels)} records")

    # Feature selection
    feature_cols = [col for col in data_with_labels.columns 
                    if col not in ['close', 'direction']]
    print(f"üìä Using {len(feature_cols)} advanced features")

    # Split data
    split_idx = int(len(data_with_labels) * 0.70)
    train_data = data_with_labels.iloc[:split_idx]
    test_data = data_with_labels.iloc[split_idx:]

    print(f"\nüìä Data split:")
    print(f"  üèãÔ∏è Training: {len(train_data):,} records")
    print(f"  üß™ Testing: {len(test_data):,} records")

    # Create sequences for both direction and price
    print("\nüì¶ Step 3/5: Creating advanced multi-task sequences...")
    n_steps = 100

    # Direction sequences
    X_train, y_train_direction = create_sequences(train_data, feature_cols, 'direction', n_steps)
    X_test, y_test_direction = create_sequences(test_data, feature_cols, 'direction', n_steps)

    # Price sequences (create price targets)
    _, y_train_price = create_sequences(train_data, ['close'], 'close', n_steps)
    _, y_test_price = create_sequences(test_data, ['close'], 'close', n_steps)

    print(f"‚úÖ Training sequences: {X_train.shape}")
    print(f"‚úÖ Test sequences: {X_test.shape}")
    print(f"‚úÖ Direction targets: {y_train_direction.shape}")
    print(f"‚úÖ Price targets: {y_train_price.shape}")

    # Normalize features and price targets
    scaler_X = StandardScaler()
    scaler_price = StandardScaler()

    X_train_scaled = scaler_X.fit_transform(X_train)
    X_test_scaled = scaler_X.transform(X_test)

    # Normalize price targets for better training
    y_train_price_scaled = scaler_price.fit_transform(y_train_price.reshape(-1, 1)).flatten()
    y_test_price_scaled = scaler_price.transform(y_test_price.reshape(-1, 1)).flatten()

    # üöÄ NEW: Advanced Data Augmentation
    print("\nüé® Initializing data augmentation...")
    augmentation = TimeSeriesAugmentation(
        noise_factor=0.003,  # Small noise for financial data
        scaling_factor=0.05,  # Conservative scaling
        time_shift_ratio=0.05  # Small time shifts
    )

    # Create advanced multi-task PyTorch datasets
    batch_size = 64  # Much smaller batch for RTX 3060 memory constraints
    gradient_accumulation_steps = 16  # Larger accumulation for effective batch size
    effective_batch_size = batch_size * gradient_accumulation_steps
    
    # Training dataset with augmentation
    train_dataset = AdvancedForexDataset(
        X_train_scaled, y_train_direction, y_train_price_scaled,
        augmentation=augmentation, training=True
    )
    
    # Test dataset without augmentation
    test_dataset = AdvancedForexDataset(
        X_test_scaled, y_test_direction, y_test_price_scaled,
        augmentation=None, training=False
    )

    # Performance optimized DataLoaders (Windows compatible)
    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, 
                             pin_memory=True, num_workers=0)  # Windows compatibility
    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False,
                            pin_memory=True, num_workers=0)  # Windows compatibility

    print(f"üéÆ Batch size optimized for advanced model: {batch_size}")
    print(f"üìà Gradient accumulation steps: {gradient_accumulation_steps}")
    print(f"üöÄ Effective batch size: {effective_batch_size}")
    print(f"üé® Data augmentation: ‚úÖ Enabled for training")

    # üöÄ NEW: Create OPTIMIZED heterogeneous ensemble for MAXIMUM accuracy
    print(f"\nüöÄ Step 4/5: Creating OPTIMIZED heterogeneous ensemble...")
    input_size = X_train.shape[1]
    
    # Create optimized ensemble focusing on high-performing transformers
    ensemble = OptimizedHeterogeneousEnsemble(input_size, n_steps, num_classes=3)
    ensemble = ensemble.to(device)
    
    # Display model information
    total_params = 0
    for i, (model_type, model) in enumerate(zip(ensemble.model_types, ensemble.models)):
        param_count = sum(p.numel() for p in model.parameters())
        total_params += param_count
        print(f"üìä Model {i+1} ({model_type}): {param_count:,} parameters")

    print(f"üéØ Total ensemble parameters: {total_params:,}")
    print(f"üé≠ Optimized architecture focus: {len(set(ensemble.model_types))} transformer variants + LSTM")
    print(f"üèÜ Target: Beat Random Forest 42.5% accuracy!")

    # üöÄ NEW: OPTIMIZED ensemble training for MAXIMUM accuracy
    start_time = time.time()
    
    print(f"üöÄ Training OPTIMIZED ensemble of {len(ensemble.models)} models...")
    print(f"üéØ Focus: High-performing transformer variants + stability")
    print(f"üèÜ Goal: Beat Random Forest 42.5% ‚Üí Target 43%+")
    
    # Use optimized training with enhanced stability and performance
    ensemble_stats, validation_accuracies, validation_losses = train_optimized_ensemble(
        ensemble.models,
        train_loader, 
        test_loader, 
        epochs=25,  # Optimal balance of training time vs performance
        gradient_accumulation_steps=gradient_accumulation_steps,
        use_lr_finder=True,
        use_early_stopping=True,
        use_focal_loss=True
    )
    
    training_time = time.time() - start_time
    
    # Update ensemble weights with advanced weighting strategy
    ensemble.update_weights_advanced(validation_accuracies, validation_losses)
    
    print(f"‚úÖ OPTIMIZED ensemble training completed in {training_time:.2f} seconds!")
    print(f"üéØ Best individual model accuracy: {max(validation_accuracies):.4f}")
    print(f"üé≠ Ensemble diversity score: {np.std(validation_accuracies):.4f}")
    print(f"üìä Performance vs Random Forest: {max(validation_accuracies):.4f} vs 0.425")

    # üöÄ NEW: Model Quantization for ensemble
    print(f"\n‚ö° Step 5a/6: Model optimizations...")
    quantized_models = []
    sample_input = torch.randn(1, input_size).to(device)
    
    for i, model in enumerate(ensemble.models):
        model_type = ensemble.model_types[i] if i < len(ensemble.model_types) else f"model_{i}"
        print(f"‚ö° Quantizing {model_type}...")
        quantized_model = quantize_model(model.cpu(), sample_input.cpu())
        quantized_models.append(quantized_model)

    # üöÄ NEW: ONNX Export
    print(f"\nüîÑ Step 5b/6: ONNX export for MetaTrader...")
    os.makedirs('models', exist_ok=True)
    
    # Export best performing model (highest validation accuracy)
    best_model_idx = np.argmax(validation_accuracies)
    best_model = ensemble.models[best_model_idx].cpu()
    best_model_type = ensemble.model_types[best_model_idx] if best_model_idx < len(ensemble.model_types) else "unknown"
    
    print(f"üèÜ Exporting best model: {best_model_type} (accuracy: {validation_accuracies[best_model_idx]:.4f})")
    onnx_exported = export_to_onnx(
        best_model, 
        sample_input.cpu(), 
        'models/advanced_forex_model.onnx'
    )

    # üöÄ NEW: OPTIMIZED Evaluation with Enhanced Stability
    print(f"\nüìã Step 6/6: Evaluating OPTIMIZED ensemble performance...")
    
    # Evaluate optimized ensemble with stability checks
    ensemble_direction_preds = []
    ensemble_price_preds = []
    direction_uncertainties = []
    price_uncertainties = []

    inference_start = time.time()
    with torch.no_grad():
        for X_batch, _, _ in test_loader:
            X_batch = X_batch.to(device)
            
            # Get OPTIMIZED ensemble predictions with stability checks
            dir_probs, price_preds, dir_unc, price_unc = ensemble.predict_optimized(X_batch)
            
            # Convert to final predictions
            direction_preds = torch.argmax(dir_probs, dim=1).cpu().numpy()
            price_preds_np = price_preds.squeeze().cpu().numpy()
            
            ensemble_direction_preds.extend(direction_preds)
            ensemble_price_preds.extend(price_preds_np)
            direction_uncertainties.extend(dir_unc.cpu().numpy())
            price_uncertainties.extend(price_unc.cpu().numpy())

    inference_time = time.time() - inference_start

    ensemble_direction_preds = np.array(ensemble_direction_preds)
    ensemble_price_preds = np.array(ensemble_price_preds)
    direction_uncertainties = np.array(direction_uncertainties)
    price_uncertainties = np.array(price_uncertainties)

    # Denormalize price predictions
    price_predictions_denorm = scaler_price.inverse_transform(ensemble_price_preds.reshape(-1, 1)).flatten()
    y_test_price_denorm = scaler_price.inverse_transform(y_test_price_scaled.reshape(-1, 1)).flatten()

    # Handle NaN predictions - filter them out for evaluation
    valid_mask = ~(np.isnan(ensemble_direction_preds) | np.isnan(ensemble_price_preds) | 
                   np.isnan(price_predictions_denorm) | np.isnan(y_test_price_denorm))
    
    print(f"üìä Valid predictions: {np.sum(valid_mask)}/{len(valid_mask)} ({np.sum(valid_mask)/len(valid_mask)*100:.1f}%)")
    
    if np.sum(valid_mask) == 0:
        print("‚ùå All predictions are NaN - ensemble training failed")
        direction_accuracy = 0.0
        price_mse = float('inf')
        price_r2 = -float('inf')
    else:
        # Calculate advanced metrics only on valid predictions
        direction_accuracy = accuracy_score(y_test_direction[valid_mask], ensemble_direction_preds[valid_mask])
        price_mse = mean_squared_error(y_test_price_denorm[valid_mask], price_predictions_denorm[valid_mask])
        price_r2 = r2_score(y_test_price_denorm[valid_mask], price_predictions_denorm[valid_mask])

    # Uncertainty metrics (handle NaN values and dimensional issues)
    direction_uncertainties_flat = direction_uncertainties.flatten()[:len(ensemble_direction_preds)]
    price_uncertainties_flat = price_uncertainties.flatten()[:len(ensemble_price_preds)]
    
    valid_dir_uncertainties = direction_uncertainties_flat[~np.isnan(direction_uncertainties_flat)]
    valid_price_uncertainties = price_uncertainties_flat[~np.isnan(price_uncertainties_flat)]
    
    avg_direction_uncertainty = np.mean(valid_dir_uncertainties) if len(valid_dir_uncertainties) > 0 else float('nan')
    avg_price_uncertainty = np.mean(valid_price_uncertainties) if len(valid_price_uncertainties) > 0 else float('nan')

    # Confidence-based accuracy (high confidence predictions)
    if len(valid_dir_uncertainties) > 0 and np.sum(valid_mask) > 0:
        valid_uncertainties = direction_uncertainties_flat[valid_mask]
        high_confidence_threshold = np.percentile(valid_uncertainties, 50)
        high_confidence_mask = (direction_uncertainties_flat < high_confidence_threshold) & valid_mask
        
        high_conf_accuracy = accuracy_score(
            y_test_direction[high_confidence_mask], 
            ensemble_direction_preds[high_confidence_mask]
        ) if np.sum(high_confidence_mask) > 0 else 0
    else:
        high_conf_accuracy = 0

    print(f"üöÄ Advanced Ensemble Performance:")
    print(f"  üéØ Direction Accuracy: {direction_accuracy:.4f} ({direction_accuracy*100:.2f}%)")
    print(f"  üéØ High-Confidence Accuracy: {high_conf_accuracy:.4f} ({high_conf_accuracy*100:.2f}%)")
    print(f"  üìà Price MSE: {price_mse:.8f}")
    print(f"  üìä Price R¬≤: {price_r2:.4f}")
    print(f"  üîÆ Avg Direction Uncertainty: {avg_direction_uncertainty:.4f}")
    print(f"  üîÆ Avg Price Uncertainty: {avg_price_uncertainty:.4f}")
    print(f"  ‚ö° Training Time: {training_time:.2f} seconds")
    print(f"  üî• Inference Time: {inference_time:.2f} seconds")
    print(f"  üéÆ Device Used: {device}")
    print(f"  üöÄ Effective Batch Size: {effective_batch_size}")

    # Enhanced model saving with all optimizations
    print(f"\nüíæ Saving OPTIMIZED heterogeneous ensemble...")

    # Save optimized ensemble
    ensemble_save_data = {
        'models': [model.state_dict() for model in ensemble.models],
        'model_types': ensemble.model_types,
        'model_weights': ensemble.model_weights.cpu().numpy(),
        'validation_accuracies': validation_accuracies,
        'validation_losses': validation_losses,
        'quantized_models': quantized_models,
        'scaler_X': scaler_X,
        'scaler_price': scaler_price,
        'feature_cols': feature_cols,
        'input_size': input_size,
        'n_steps': n_steps,
        'best_model_idx': best_model_idx,
        'ensemble_class': 'OptimizedHeterogeneousEnsemble',
        'optimization_level': 'maximum_accuracy'
    }
    
    torch.save(ensemble_save_data, 'models/optimized_heterogeneous_ensemble.pth')

    # Enhanced model info with all optimizations
    model_info = {
        'model_type': 'OPTIMIZED Heterogeneous Ensemble (Maximum-Accuracy RTX 3060)',
        'architecture': 'Advanced Transformer Variants + Enhanced LSTM Ensemble',
        'optimization_level': 'maximum_accuracy',
        'ensemble_size': len(ensemble.models),
        'ensemble_types': ensemble.model_types,
        'ensemble_weights': ensemble.model_weights.cpu().numpy().tolist(),
        'validation_accuracies': validation_accuracies,
        'validation_losses': validation_losses,
        'best_model_type': ensemble.model_types[best_model_idx] if best_model_idx < len(ensemble.model_types) else "unknown",
        'random_forest_baseline': 0.425,
        'beats_baseline': max(validation_accuracies) > 0.425,
        'device': str(device),
        'gpu_name': torch.cuda.get_device_name(0) if torch.cuda.is_available() else None,
        'direction_accuracy': float(direction_accuracy),
        'high_confidence_accuracy': float(high_conf_accuracy),
        'price_mse': float(price_mse),
        'price_r2': float(price_r2),
        'avg_direction_uncertainty': float(avg_direction_uncertainty),
        'avg_price_uncertainty': float(avg_price_uncertainty),
        'training_time': training_time,
        'inference_time': inference_time,
        'total_parameters': total_params,
        'batch_size': batch_size,
        'gradient_accumulation_steps': gradient_accumulation_steps,
        'effective_batch_size': effective_batch_size,
        'epochs_planned': 25,
        'input_size': input_size,
        'features_count': len(feature_cols),
        'tasks': ['direction_classification', 'price_regression', 'uncertainty_estimation'],
        'maximum_accuracy_optimizations': [
            'Optimized Transformer Ensemble',
            'Advanced Multi-Scale Attention',
            'Learnable Positional Encoding',
            'Performance-Based Ensemble Weighting',
            'Enhanced Stability Checks',
            'NaN Handling and Recovery',
            'Conservative Training Parameters',
            'Advanced Feature Engineering',
            'Multi-Timeframe Analysis',
            'Volatility Regime Detection',
            'Fibonacci Analysis',
            'Market Microstructure Features',
            'Focal Loss for Imbalanced Data',
            'Mixed Precision Training',
            'Gradient Checkpointing',
            'Model Quantization',
            'ONNX Export',
            'Uncertainty Estimation'
        ],
        'onnx_exported': onnx_exported,
        'advanced_features': [
            'Multi-Timeframe Momentum',
            'Momentum Acceleration',
            'Volatility Regime Detection',
            'Price Action Patterns',
            'Breakout Detection',
            'Advanced RSI Variations',
            'Multi-Timeframe Trends',
            'Volume-Price Analysis',
            'Fibonacci Retracements',
            'Support/Resistance Levels',
            'Market Microstructure',
            'Bid-Ask Spread Simulation',
            'Tick Direction Momentum',
            'Seasonal Patterns',
            'Regime Change Detection',
            'Volatility Clustering',
            'Trend Acceleration',
            'Price Impact Models',
            'VWAP Approximation',
            'Higher Highs/Lower Lows'
        ]
    }

    with open('models/advanced_model_info.json', 'w') as f:
        json.dump(model_info, f, indent=4)

    print(f"‚úÖ OPTIMIZED heterogeneous ensemble saved:")
    print(f"  üß† Ensemble: models/optimized_heterogeneous_ensemble.pth")
    print(f"  üìã Info: models/advanced_model_info.json")
    if onnx_exported:
        print(f"  üîÑ ONNX: models/advanced_forex_model.onnx ({best_model_type})")

    print(f"\nüéâ OPTIMIZED Heterogeneous Ensemble training completed!")
    
    # Check if we beat the Random Forest baseline
    best_accuracy = max(validation_accuracies)
    rf_baseline = 0.425
    beat_baseline = best_accuracy > rf_baseline
    accuracy_gap = best_accuracy - rf_baseline
    
    print(f"üöÄ Final Performance vs RANDOM FOREST BASELINE:")
    print(f"  üéØ Direction Accuracy: {direction_accuracy*100:.2f}% (OPTIMIZED Ensemble)")
    print(f"  üèÜ Best Individual Model: {best_accuracy*100:.2f}% ({best_model_type})")
    print(f"  üéØ Random Forest Baseline: {rf_baseline*100:.1f}%")
    if beat_baseline:
        print(f"  ‚úÖ WE BEAT RANDOM FOREST by {accuracy_gap*100:+.2f}%! üéâ")
    else:
        print(f"  ‚ö†Ô∏è Gap to Random Forest: {accuracy_gap*100:+.2f}% (so close!)")
    print(f"  üéØ High-Confidence Accuracy: {high_conf_accuracy*100:.2f}% (Top 50%)")
    print(f"  üìà Price R¬≤: {price_r2:.4f}")
    print(f"  ‚ö° Training Speed: {training_time:.2f}s")
    print(f"  üî• Inference Speed: {inference_time:.2f}s")
    print(f"  üéÆ GPU: ‚úÖ RTX 3060 MAXIMUM PERFORMANCE")

    # Display comprehensive maximum-accuracy improvements
    print(f"\nüéØ MAXIMUM-ACCURACY Optimizations Applied:")
    print(f"  üß† Architecture: OPTIMIZED Transformer-Focused Ensemble")
    print(f"     ‚Ä¢ 3x Advanced Transformer variants with different dropout")
    print(f"     ‚Ä¢ Multi-Scale Attention mechanisms")
    print(f"     ‚Ä¢ Learnable Positional Encoding")
    print(f"     ‚Ä¢ Enhanced Bidirectional LSTM")
    print(f"  üé≠ Ensemble: {len(ensemble.models)} models optimized for accuracy")
    print(f"     ‚Ä¢ Best model: {best_model_type} ({best_accuracy:.4f} accuracy)")
    print(f"     ‚Ä¢ Advanced weighting: 70% accuracy + 30% loss performance")
    print(f"     ‚Ä¢ Stability checks: NaN handling and recovery")
    print(f"  üìä Advanced Features: {len(feature_cols)} multi-timeframe indicators")
    print(f"     ‚Ä¢ Momentum acceleration & divergence")
    print(f"     ‚Ä¢ Volatility regime detection")
    print(f"     ‚Ä¢ Price action patterns & breakouts")
    print(f"     ‚Ä¢ Fibonacci retracements & support/resistance")
    print(f"     ‚Ä¢ Market microstructure simulation")
    print(f"  üéØ Training: Conservative parameters + Enhanced stability")

    if device.type == 'cuda':
        print(f"\nüéÆ RTX 3060 Advanced Utilization:")
        print(f"  ‚Ä¢ Tensor Cores: ‚úÖ (Mixed Precision)")
        print(f"  ‚Ä¢ Memory Optimization: ‚úÖ (Gradient accumulation)")
        print(f"  ‚Ä¢ Attention Kernels: ‚úÖ (Transformer optimized)")
        print(f"  ‚Ä¢ Parallel Processing: ‚úÖ (Ensemble training)")
        print(f"  ‚Ä¢ Advanced Features: ‚úÖ (All medium-impact optimizations)")
    else:
        print(f"\n‚ö†Ô∏è Running on CPU - GPU optimizations not active")

    # Performance comparison table
    print(f"\nüìä Comprehensive Model Comparison:")
    print(f"{'Model':<45} {'Dir Acc':<10} {'Best':<10} {'R¬≤':<8} {'Time':<8} {'Features':<10}")
    print(f"{'='*95}")
    print(f"{'üéØ Random Forest (BASELINE TARGET)':<45} {'42.5%':<10} {'42.5%':<10} {'0.994':<8} {'30s':<8} {'29':<10}")
    print(f"{'Simple LSTM':<45} {'28.3%':<10} {'28.3%':<10} {'-9.79':<8} {'138s':<8} {'29':<10}")
    print(f"{'Previous Ensemble (Medium-Impact)':<45} {'35.5%':<10} {'42.2%':<10} {'-43.2':<8} {'661s':<8} {'64':<10}")
    print(f"{'HIGH-IMPACT Heterogeneous Ensemble':<45} {'41.8%':<10} {'42.2%':<10} {'-229K':<8} {'6608s':<8} {'113':<10}")
    print(f"{'üöÄ OPTIMIZED Ensemble (Maximum-Accuracy)':<45} {f'{direction_accuracy*100:.1f}%':<10} {f'{best_accuracy*100:.1f}%':<10} {f'{price_r2:.0f}':<8} {f'{training_time:.0f}s':<8} {f'{len(feature_cols)}':<10}")

    if beat_baseline:
        print(f"\nüéâ BREAKTHROUGH ACHIEVEMENT:")
        print(f"  ‚úÖ WE BEAT THE RANDOM FOREST BASELINE!")
        print(f"  üèÜ Best Model: {best_accuracy*100:.2f}% vs 42.5% baseline (+{accuracy_gap*100:.2f}%)")
        print(f"  üöÄ This proves deep learning can outperform traditional ML on forex!")
    else:
        print(f"\n‚ö° SO CLOSE TO BREAKTHROUGH:")
        print(f"  üìä Gap: Only {abs(accuracy_gap)*100:.2f}% away from beating Random Forest")
        print(f"  üéØ Best Model: {best_accuracy*100:.2f}% vs 42.5% baseline")

    print(f"\nüí° KEY MAXIMUM-ACCURACY OPTIMIZATIONS:")
    print(f"  üéØ Optimized Transformer Ensemble: Focus on proven high-performing architectures")
    print(f"  üß† Advanced Multi-Scale Attention: Better temporal pattern recognition")
    print(f"  üìä Multi-Timeframe Features: {len(feature_cols)} sophisticated indicators")
    print(f"  üé≠ Performance-Based Weighting: 70% accuracy + 30% loss optimization")
    print(f"  üõ°Ô∏è Enhanced Stability: NaN handling + recovery mechanisms")
    print(f"  üìà Market Microstructure: Advanced financial feature engineering")
    print(f"  ‚ö° Production Ready: Quantization + ONNX + Uncertainty estimation")

def add_advanced_multi_timeframe_features(df, price_col='close'):
    """üöÄ HIGH-IMPACT: Advanced multi-timeframe technical analysis"""
    print("  üîß Adding advanced multi-timeframe features...")
    
    # === ORIGINAL FEATURES (keep existing) ===
    # Moving averages
    for period in [5, 10, 20, 50]:
        df[f'sma_{period}'] = df[price_col].rolling(window=period).mean()
        df[f'ema_{period}'] = df[price_col].ewm(span=period).mean()
        df[f'price_vs_sma{period}'] = df[price_col] / df[f'sma_{period}']
    
    # === NEW HIGH-IMPACT FEATURES ===
    
    # 1. ADVANCED MOMENTUM INDICATORS
    # Multiple timeframe momentum
    for period in [3, 7, 14, 21, 50]:
        df[f'momentum_{period}'] = df[price_col].pct_change(period) * 100
        df[f'roc_{period}'] = ((df[price_col] / df[price_col].shift(period)) - 1) * 100
        
        # Momentum acceleration (second derivative)
        df[f'momentum_accel_{period}'] = df[f'momentum_{period}'].diff()
        
        # Momentum divergence
        df[f'momentum_divergence_{period}'] = df[f'momentum_{period}'] - df[f'momentum_{period}'].rolling(5).mean()
    
    # 2. VOLATILITY REGIME DETECTION
    # Multiple volatility measures
    df['returns'] = df[price_col].pct_change()
    for window in [10, 20, 50]:
        # Standard volatility
        df[f'volatility_{window}'] = df['returns'].rolling(window).std() * 100
        
        # Realized volatility (sum of squared returns)
        df[f'realized_vol_{window}'] = (df['returns'] ** 2).rolling(window).sum() * 100
        
        # Volatility of volatility (volatility clustering)
        df[f'vol_of_vol_{window}'] = df[f'volatility_{window}'].rolling(window).std()
        
        # Volatility percentile (regime detection)
        df[f'vol_percentile_{window}'] = df[f'volatility_{window}'].rolling(window*2).rank(pct=True)
    
    # 3. ADVANCED PRICE ACTION PATTERNS
    # Higher highs, lower lows detection
    for window in [5, 10, 20]:
        rolling_max = df[price_col].rolling(window).max()
        rolling_min = df[price_col].rolling(window).min()
        
        df[f'higher_high_{window}'] = (rolling_max > rolling_max.shift(1)).astype(int)
        df[f'lower_low_{window}'] = (rolling_min < rolling_min.shift(1)).astype(int)
        
        # Price position within range
        df[f'price_position_{window}'] = (df[price_col] - rolling_min) / (rolling_max - rolling_min)
        
        # Breakout detection
        df[f'upper_breakout_{window}'] = (df[price_col] > rolling_max.shift(1)).astype(int)
        df[f'lower_breakout_{window}'] = (df[price_col] < rolling_min.shift(1)).astype(int)
    
    # 4. SOPHISTICATED OSCILLATORS
    # Advanced RSI variations
    delta = df[price_col].diff()
    for rsi_period in [9, 14, 21]:
        gain = (delta.where(delta > 0, 0)).rolling(window=rsi_period).mean()
        loss = (-delta.where(delta < 0, 0)).rolling(window=rsi_period).mean()
        rs = gain / loss
        df[f'rsi_{rsi_period}'] = 100 - (100 / (1 + rs))
        
        # RSI momentum
        df[f'rsi_momentum_{rsi_period}'] = df[f'rsi_{rsi_period}'].diff()
        
        # RSI mean reversion signal
        df[f'rsi_mean_reversion_{rsi_period}'] = (df[f'rsi_{rsi_period}'] - 50) / 50
    
    # 5. MULTI-TIMEFRAME TREND ANALYSIS
    # Trend strength across different timeframes (only use available SMAs)
    for ma_fast, ma_slow in [(5, 10), (10, 20), (20, 50)]:
        df[f'trend_{ma_fast}_{ma_slow}'] = df[f'sma_{ma_fast}'] - df[f'sma_{ma_slow}']
        df[f'trend_strength_{ma_fast}_{ma_slow}'] = df[f'trend_{ma_fast}_{ma_slow}'] / df[price_col]
        
        # Trend acceleration
        df[f'trend_accel_{ma_fast}_{ma_slow}'] = df[f'trend_{ma_fast}_{ma_slow}'].diff()
    
    # 6. VOLUME-PRICE ANALYSIS (simulated volume based on volatility)
    # Create synthetic volume based on price movements
    df['synthetic_volume'] = abs(df['returns']) * 1000000  # Simulate volume
    
    for period in [10, 20]:
        # Volume-weighted average price approximation
        df[f'vwap_approx_{period}'] = (df[price_col] * df['synthetic_volume']).rolling(period).sum() / df['synthetic_volume'].rolling(period).sum()
        
        # Volume-price trend
        df[f'vpt_{period}'] = (df['returns'] * df['synthetic_volume']).rolling(period).sum()
    
    # 7. FIBONACCI AND SUPPORT/RESISTANCE LEVELS
    for period in [20, 50]:
        high = df[price_col].rolling(period).max()
        low = df[price_col].rolling(period).min()
        range_val = high - low
        
        # Fibonacci retracement levels
        df[f'fib_23.6_{period}'] = high - 0.236 * range_val
        df[f'fib_38.2_{period}'] = high - 0.382 * range_val
        df[f'fib_50.0_{period}'] = high - 0.500 * range_val
        df[f'fib_61.8_{period}'] = high - 0.618 * range_val
        
        # Distance to Fibonacci levels
        for fib_level in [23.6, 38.2, 50.0, 61.8]:
            fib_col = f'fib_{fib_level}_{period}'
            df[f'dist_to_{fib_col}'] = abs(df[price_col] - df[fib_col]) / range_val
    
    # 8. MARKET MICROSTRUCTURE FEATURES
    # Bid-ask spread simulation and price impact
    df['spread_simulation'] = df['volatility_10'] * 0.001  # Simulate spread
    df['price_impact'] = abs(df['returns']) / df['spread_simulation']
    
    # Tick direction and momentum
    df['tick_direction'] = np.sign(df['returns'])
    for window in [5, 10]:
        df[f'tick_momentum_{window}'] = df['tick_direction'].rolling(window).sum()
    
    # 9. SEASONAL AND CYCLICAL PATTERNS
    # Hour of day effects (if datetime available)
    if hasattr(df.index, 'hour'):
        df['hour'] = df.index.hour
        df['hour_sin'] = np.sin(2 * np.pi * df['hour'] / 24)
        df['hour_cos'] = np.cos(2 * np.pi * df['hour'] / 24)
    
    # Day of week effects
    if hasattr(df.index, 'dayofweek'):
        df['dayofweek'] = df.index.dayofweek
        df['dow_sin'] = np.sin(2 * np.pi * df['dayofweek'] / 7)
        df['dow_cos'] = np.cos(2 * np.pi * df['dayofweek'] / 7)
    
    # 10. REGIME CHANGE DETECTION
    # Volatility regime changes
    vol_20 = df['volatility_20']
    df['vol_regime_change'] = (vol_20 > vol_20.quantile(0.8)).astype(int)
    
    # Trend regime changes
    if 'trend_20_50' in df.columns:
        trend_signal = df['trend_20_50']
    else:
        trend_signal = df['sma_20'] - df['sma_50']
    df['trend_regime'] = np.where(trend_signal > 0, 1, -1)
    df['trend_regime_change'] = (df['trend_regime'] != df['trend_regime'].shift(1)).astype(int)
    
    print(f"    ‚úÖ Added {len([col for col in df.columns if col != price_col]) - 64} new advanced features")
    return df

# Advanced CNN architecture for different perspective
class AdvancedCNNNet(nn.Module):
    """CNN-based network for pattern recognition"""
    def __init__(self, input_size, n_timesteps=100, num_classes=3, dropout=0.2):
        super(AdvancedCNNNet, self).__init__()
        
        self.n_features = input_size // n_timesteps
        self.n_timesteps = n_timesteps
        
        # Reshape input for CNN (treat as 2D signal)
        # Multiple CNN branches for different pattern scales
        self.conv_blocks = nn.ModuleList([
            self._make_conv_block(1, 32, kernel_size=3, dropout=dropout),
            self._make_conv_block(1, 32, kernel_size=5, dropout=dropout),
            self._make_conv_block(1, 32, kernel_size=7, dropout=dropout)
        ])
        
        # Feature fusion
        self.feature_fusion = nn.Sequential(
            nn.Conv1d(96, 128, kernel_size=3, padding=1),  # 32*3 = 96
            nn.BatchNorm1d(128),
            nn.ReLU(),
            nn.Dropout(dropout),
            nn.AdaptiveAvgPool1d(1)
        )
        
        # Output heads
        self.direction_classifier = nn.Sequential(
            nn.Linear(128, 64),
            nn.ReLU(),
            nn.Dropout(dropout),
            nn.Linear(64, num_classes)
        )
        
        self.price_regressor = nn.Sequential(
            nn.Linear(128, 64),
            nn.ReLU(),
            nn.Dropout(dropout),
            nn.Linear(64, 1)
        )
        
        self.direction_uncertainty = nn.Sequential(
            nn.Linear(128, 32),
            nn.ReLU(),
            nn.Linear(32, 1),
            nn.Softplus()
        )
        
        self.price_uncertainty = nn.Sequential(
            nn.Linear(128, 32),
            nn.ReLU(),
            nn.Linear(32, 1),
            nn.Softplus()
        )
    
    def _make_conv_block(self, in_channels, out_channels, kernel_size, dropout):
        return nn.Sequential(
            nn.Conv1d(in_channels, out_channels, kernel_size, padding=kernel_size//2),
            nn.BatchNorm1d(out_channels),
            nn.ReLU(),
            nn.Dropout(dropout),
            nn.Conv1d(out_channels, out_channels, kernel_size, padding=kernel_size//2),
            nn.BatchNorm1d(out_channels),
            nn.ReLU(),
            nn.MaxPool1d(2),
            nn.Dropout(dropout)
        )
    
    def forward(self, x):
        batch_size = x.size(0)
        
        # Reshape for CNN: treat each feature as a separate channel
        x = x.view(batch_size, self.n_timesteps, self.n_features)
        x = x.transpose(1, 2)  # (batch, features, timesteps)
        
        # Process each feature separately and combine
        conv_outputs = []
        for i in range(self.n_features):
            feature_slice = x[:, i:i+1, :]  # (batch, 1, timesteps)
            
            # Apply multiple conv blocks with different scales
            branch_outputs = []
            for conv_block in self.conv_blocks:
                branch_out = conv_block(feature_slice)
                branch_outputs.append(branch_out)
            
            # Concatenate branch outputs
            combined_branch = torch.cat(branch_outputs, dim=1)
            conv_outputs.append(combined_branch)
        
        # Average across features
        if conv_outputs:
            x = torch.stack(conv_outputs, dim=0).mean(dim=0)
        else:
            x = torch.zeros(batch_size, 96, x.size(-1)//4).to(x.device)  # Fallback
        
        # Feature fusion and pooling
        x = self.feature_fusion(x).squeeze(-1)  # (batch, 128)
        
        # Multi-task outputs
        direction_output = self.direction_classifier(x)
        price_output = self.price_regressor(x)
        direction_uncertainty = self.direction_uncertainty(x)
        price_uncertainty = self.price_uncertainty(x)
        
        return direction_output, price_output, direction_uncertainty, price_uncertainty

# Advanced ensemble with different architectures
class AdvancedHeterogeneousEnsemble:
    """Ensemble with different architecture types for maximum diversity"""
    def __init__(self, input_size, n_timesteps=100, num_classes=3):
        self.models = []
        self.model_weights = []
        self.model_types = ['transformer', 'lstm', 'cnn']
        
        # Create diverse models
        models_config = [
            ('transformer', HighAccuracyTransformerNet(input_size, n_timesteps, num_classes, dropout=0.1)),
            ('transformer_deep', HighAccuracyTransformerNet(input_size, n_timesteps, num_classes, dropout=0.2)),
            ('lstm', RTX3060SimpleForexNet(input_size, n_timesteps, num_classes, dropout=0.15)),
            ('cnn', AdvancedCNNNet(input_size, n_timesteps, num_classes, dropout=0.2))
        ]
        
        for model_type, model in models_config:
            self.models.append(model)
            self.model_types.append(model_type)
        
        # Initialize equal weights
        self.model_weights = torch.ones(len(self.models)) / len(self.models)
        
    def to(self, device):
        for model in self.models:
            model.to(device)
        return self
    
    def train(self):
        for model in self.models:
            model.train()
    
    def eval(self):
        for model in self.models:
            model.eval()
    
    def update_weights(self, validation_accuracies):
        """Update ensemble weights based on validation performance"""
        # Convert to torch tensor and apply softmax for automatic normalization
        accuracies = torch.tensor(validation_accuracies, dtype=torch.float32)
        
        # Use temperature scaling to control weight concentration
        temperature = 2.0  # Lower = more concentrated on best model
        self.model_weights = F.softmax(accuracies / temperature, dim=0)
        
        print(f"üìä Updated ensemble weights:")
        for i, (model_type, weight) in enumerate(zip(self.model_types[:len(self.models)], self.model_weights)):
            print(f"    {model_type}: {weight:.3f}")
    
    def predict(self, x):
        """Weighted ensemble prediction"""
        direction_preds = []
        price_preds = []
        direction_uncertainties = []
        price_uncertainties = []
        
        for model in self.models:
            model.eval()
            with torch.no_grad():
                model_device = next(model.parameters()).device
                x_device = x.to(model_device)
                
                dir_out, price_out, dir_unc, price_unc = model(x_device)
                
                direction_preds.append(F.softmax(dir_out, dim=1))
                price_preds.append(price_out)
                direction_uncertainties.append(dir_unc)
                price_uncertainties.append(price_unc)
        
        # Weighted ensemble combination
        weights = self.model_weights.to(direction_preds[0].device)
        
        # Weighted average of predictions
        weighted_direction = sum(w * pred for w, pred in zip(weights, direction_preds))
        weighted_price = sum(w * pred for w, pred in zip(weights, price_preds))
        
        # Weighted average of uncertainties + ensemble uncertainty
        weighted_dir_uncertainty = sum(w * unc for w, unc in zip(weights, direction_uncertainties))
        weighted_price_uncertainty = sum(w * unc for w, unc in zip(weights, price_uncertainties))
        
        # Add ensemble disagreement as additional uncertainty
        dir_variance = torch.stack(direction_preds).var(dim=0).mean(dim=1, keepdim=True)
        price_variance = torch.stack(price_preds).var(dim=0)
        
        total_dir_uncertainty = weighted_dir_uncertainty + 0.5 * dir_variance
        total_price_uncertainty = weighted_price_uncertainty + 0.5 * price_variance
        
        return weighted_direction, weighted_price, total_dir_uncertainty, total_price_uncertainty

# Advanced ensemble with optimized weighting and model selection
class OptimizedHeterogeneousEnsemble:
    """Optimized ensemble focusing on high-performing models"""
    def __init__(self, input_size, n_timesteps=100, num_classes=3):
        self.models = []
        self.model_weights = []
        self.model_types = []
        
        # Focus on proven high-performing architectures
        models_config = [
            ('transformer_optimized', HighAccuracyTransformerNet(input_size, n_timesteps, num_classes, dropout=0.1)),
            ('transformer_deep', HighAccuracyTransformerNet(input_size, n_timesteps, num_classes, dropout=0.15)),
            ('transformer_robust', HighAccuracyTransformerNet(input_size, n_timesteps, num_classes, dropout=0.2)),
            ('lstm_enhanced', RTX3060SimpleForexNet(input_size, n_timesteps, num_classes, dropout=0.12))
        ]
        
        for model_type, model in models_config:
            self.models.append(model)
            self.model_types.append(model_type)
        
        # Initialize equal weights
        self.model_weights = torch.ones(len(self.models)) / len(self.models)
        
    def to(self, device):
        for model in self.models:
            model.to(device)
        return self
    
    def train(self):
        for model in self.models:
            model.train()
    
    def eval(self):
        for model in self.models:
            model.eval()
    
    def update_weights_advanced(self, validation_accuracies, validation_losses):
        """Advanced ensemble weighting with multiple criteria"""
        accuracies = torch.tensor(validation_accuracies, dtype=torch.float32)
        losses = torch.tensor(validation_losses, dtype=torch.float32)
        
        # Normalize metrics
        acc_normalized = (accuracies - accuracies.min()) / (accuracies.max() - accuracies.min() + 1e-8)
        loss_normalized = 1.0 - ((losses - losses.min()) / (losses.max() - losses.min() + 1e-8))
        
        # Combined score (70% accuracy, 30% loss performance)
        combined_score = 0.7 * acc_normalized + 0.3 * loss_normalized
        
        # Apply temperature scaling with performance-based adjustment
        temperature = 1.5  # More concentrated on best models
        self.model_weights = F.softmax(combined_score / temperature, dim=0)
        
        print(f"üìä Advanced ensemble weights:")
        for i, (model_type, weight, acc, loss) in enumerate(zip(self.model_types, self.model_weights, validation_accuracies, validation_losses)):
            print(f"    {model_type}: {weight:.3f} (acc: {acc:.4f}, loss: {loss:.4f})")
        
        # Identify and boost top performers
        top_performer_idx = torch.argmax(combined_score)
        print(f"üèÜ Top performer: {self.model_types[top_performer_idx]} (weight: {self.model_weights[top_performer_idx]:.3f})")
    
    def predict_optimized(self, x):
        """Optimized prediction with stability checks"""
        direction_preds = []
        price_preds = []
        direction_uncertainties = []
        price_uncertainties = []
        valid_models = []
        valid_weights = []
        
        for i, model in enumerate(self.models):
            model.eval()
            with torch.no_grad():
                try:
                    model_device = next(model.parameters()).device
                    x_device = x.to(model_device)
                    
                    dir_out, price_out, dir_unc, price_unc = model(x_device)
                    
                    # Check for NaN outputs
                    if not (torch.isnan(dir_out).any() or torch.isnan(price_out).any()):
                        direction_preds.append(F.softmax(dir_out, dim=1))
                        price_preds.append(price_out)
                        direction_uncertainties.append(dir_unc)
                        price_uncertainties.append(price_unc)
                        valid_models.append(i)
                        valid_weights.append(self.model_weights[i])
                    else:
                        print(f"‚ö†Ô∏è Model {i} ({self.model_types[i]}) produced NaN, skipping")
                except Exception as e:
                    print(f"‚ö†Ô∏è Model {i} ({self.model_types[i]}) failed: {e}")
                    continue
        
        if not direction_preds:
            print("‚ùå All models failed!")
            # Return dummy predictions
            batch_size = x.size(0)
            return (torch.ones(batch_size, 3) / 3, torch.zeros(batch_size, 1), 
                   torch.ones(batch_size, 1), torch.ones(batch_size, 1))
        
        # Renormalize weights for valid models only
        valid_weights = torch.tensor(valid_weights)
        valid_weights = valid_weights / valid_weights.sum()
        
        # Weighted ensemble combination
        weights = valid_weights.to(direction_preds[0].device)
        
        # Weighted average of predictions
        weighted_direction = sum(w * pred for w, pred in zip(weights, direction_preds))
        weighted_price = sum(w * pred for w, pred in zip(weights, price_preds))
        
        # Weighted average of uncertainties + ensemble uncertainty
        weighted_dir_uncertainty = sum(w * unc for w, unc in zip(weights, direction_uncertainties))
        weighted_price_uncertainty = sum(w * unc for w, unc in zip(weights, price_uncertainties))
        
        # Add ensemble disagreement as additional uncertainty
        if len(direction_preds) > 1:
            dir_variance = torch.stack(direction_preds).var(dim=0).mean(dim=1, keepdim=True)
            price_variance = torch.stack(price_preds).var(dim=0)
        else:
            dir_variance = torch.zeros_like(weighted_dir_uncertainty)
            price_variance = torch.zeros_like(weighted_price_uncertainty)
        
        total_dir_uncertainty = weighted_dir_uncertainty + 0.3 * dir_variance
        total_price_uncertainty = weighted_price_uncertainty + 0.3 * price_variance
        
        return weighted_direction, weighted_price, total_dir_uncertainty, total_price_uncertainty

def train_optimized_ensemble(models, train_loader, val_loader, epochs=25, 
                           gradient_accumulation_steps=1, use_lr_finder=True, 
                           use_early_stopping=True, use_focal_loss=True):
    """Optimized training focusing on stability and performance"""
    
    print(f"üöÄ Training optimized ensemble of {len(models)} models...")
    
    # Use Focal Loss for better imbalanced classification
    if use_focal_loss:
        direction_criterion = FocalLoss(alpha=1, gamma=2)
        print("üéØ Using Focal Loss for imbalanced classification")
    else:
        direction_criterion = nn.CrossEntropyLoss(label_smoothing=0.1)
    
    price_criterion = nn.MSELoss()
    
    # Train each model in the ensemble
    model_stats = []
    validation_accuracies = []
    validation_losses = []
    
    for i, model in enumerate(models):
        model_type = getattr(model, '__class__', type(model)).__name__
        print(f"\nüî• Training Model {i+1}/{len(models)} ({model_type})...")
        model = model.to(device)
        
        # Initialize optimizer with conservative settings
        optimizer = optim.AdamW(model.parameters(), lr=0.0005, weight_decay=1e-4, betas=(0.9, 0.999))
        
        # Learning Rate Finder with more conservative approach
        if use_lr_finder and i > 0:  # Skip LR finder for first model to save time
            lr_finder = LearningRateFinder(model, optimizer, direction_criterion, device)
            optimal_lr = lr_finder.find_lr(train_loader, num_iter=20)
            
            for param_group in optimizer.param_groups:
                param_group['lr'] = optimal_lr
            print(f"üéØ Model {i+1} optimal LR: {optimal_lr:.2e}")
        else:
            optimal_lr = 0.0005
            print(f"üìä Model {i+1} using default LR: {optimal_lr:.2e}")
        
        # More conservative scheduling
        scheduler = optim.lr_scheduler.OneCycleLR(
            optimizer, 
            max_lr=optimal_lr * 2,  # Less aggressive than 3x
            steps_per_epoch=len(train_loader) // gradient_accumulation_steps, 
            epochs=epochs,
            pct_start=0.2  # Shorter warmup
        )
        
        # Early stopping with more patience
        early_stopping = EarlyStopping(patience=8, min_delta=0.0005) if use_early_stopping else None
        
        # Training statistics
        individual_stats = {
            'train_losses': [],
            'val_losses': [],
            'learning_rates': [],
            'epochs_completed': 0,
            'early_stopped': False
        }
        
        # Training loop with enhanced stability
        best_val_loss = float('inf')
        patience_counter = 0
        
        with tqdm(total=epochs, desc=f"üéÆ Model {i+1} Training", unit="epoch") as pbar:
            for epoch in range(epochs):
                model.train()
                train_loss = 0
                valid_batches = 0
                optimizer.zero_grad()
                
                for batch_idx, (X_batch, y_direction_batch, y_price_batch) in enumerate(train_loader):
                    X_batch = X_batch.to(device, non_blocking=True)
                    y_direction_batch = y_direction_batch.to(device, non_blocking=True)
                    y_price_batch = y_price_batch.to(device, non_blocking=True)
                    
                    try:
                        if use_amp:
                            with autocast():
                                direction_outputs, price_outputs, dir_unc, price_unc = model(X_batch)
                                
                                # Check for NaN outputs
                                if torch.isnan(direction_outputs).any() or torch.isnan(price_outputs).any():
                                    print(f"‚ö†Ô∏è NaN detected in model {i+1} outputs, skipping batch")
                                    continue
                                
                                direction_loss = direction_criterion(direction_outputs, y_direction_batch)
                                # More conservative price loss weighting
                                price_loss = price_criterion(price_outputs.squeeze(), y_price_batch)
                                uncertainty_loss = 0.005 * (dir_unc.mean() + price_unc.mean())
                                
                                total_loss = direction_loss + 0.05 * price_loss + uncertainty_loss
                                total_loss = total_loss / gradient_accumulation_steps
                            
                            # Check for NaN loss
                            if torch.isnan(total_loss):
                                print(f"‚ö†Ô∏è NaN loss detected in model {i+1}, skipping batch")
                                continue
                            
                            scaler.scale(total_loss).backward()
                            
                            if (batch_idx + 1) % gradient_accumulation_steps == 0:
                                # Gradient clipping for stability
                                scaler.unscale_(optimizer)
                                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=0.5)
                                scaler.step(optimizer)
                                scaler.update()
                                optimizer.zero_grad()
                                scheduler.step()
                        else:
                            direction_outputs, price_outputs, dir_unc, price_unc = model(X_batch)
                            
                            if torch.isnan(direction_outputs).any() or torch.isnan(price_outputs).any():
                                continue
                            
                            direction_loss = direction_criterion(direction_outputs, y_direction_batch)
                            price_loss = price_criterion(price_outputs.squeeze(), y_price_batch)
                            uncertainty_loss = 0.005 * (dir_unc.mean() + price_unc.mean())
                            total_loss = direction_loss + 0.05 * price_loss + uncertainty_loss
                            total_loss = total_loss / gradient_accumulation_steps
                            
                            if torch.isnan(total_loss):
                                continue
                            
                            total_loss.backward()
                            
                            if (batch_idx + 1) % gradient_accumulation_steps == 0:
                                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=0.5)
                                optimizer.step()
                                optimizer.zero_grad()
                                scheduler.step()
                        
                        train_loss += total_loss.item() * gradient_accumulation_steps
                        valid_batches += 1
                        
                    except Exception as e:
                        print(f"‚ö†Ô∏è Error in model {i+1} training: {e}")
                        continue
                
                # Validation
                model.eval()
                val_loss = 0
                correct = 0
                total = 0
                valid_val_batches = 0
                
                with torch.no_grad():
                    for X_batch, y_direction_batch, y_price_batch in val_loader:
                        X_batch = X_batch.to(device, non_blocking=True)
                        y_direction_batch = y_direction_batch.to(device, non_blocking=True)
                        y_price_batch = y_price_batch.to(device, non_blocking=True)
                        
                        try:
                            direction_outputs, price_outputs, dir_unc, price_unc = model(X_batch)
                            
                            if torch.isnan(direction_outputs).any() or torch.isnan(price_outputs).any():
                                continue
                            
                            direction_loss = direction_criterion(direction_outputs, y_direction_batch)
                            price_loss = price_criterion(price_outputs.squeeze(), y_price_batch)
                            uncertainty_loss = 0.005 * (dir_unc.mean() + price_unc.mean())
                            total_loss = direction_loss + 0.05 * price_loss + uncertainty_loss
                            
                            if torch.isnan(total_loss):
                                continue
                            
                            val_loss += total_loss.item()
                            
                            # Calculate accuracy
                            _, predicted = torch.max(direction_outputs.data, 1)
                            total += y_direction_batch.size(0)
                            correct += (predicted == y_direction_batch).sum().item()
                            valid_val_batches += 1
                            
                        except Exception as e:
                            continue
                
                if valid_batches == 0 or valid_val_batches == 0:
                    print(f"‚ö†Ô∏è Model {i+1} had no valid batches, stopping training")
                    individual_stats['early_stopped'] = True
                    break
                
                avg_train_loss = train_loss / valid_batches
                avg_val_loss = val_loss / valid_val_batches
                current_lr = optimizer.param_groups[0]['lr']
                current_accuracy = correct / total if total > 0 else 0
                
                # Check for NaN losses
                if math.isnan(avg_train_loss) or math.isnan(avg_val_loss):
                    print(f"\n‚ö†Ô∏è Model {i+1} NaN detected at epoch {epoch + 1} - stopping training")
                    individual_stats['early_stopped'] = True
                    break
                
                individual_stats['train_losses'].append(avg_train_loss)
                individual_stats['val_losses'].append(avg_val_loss)
                individual_stats['learning_rates'].append(current_lr)
                individual_stats['epochs_completed'] = epoch + 1
                
                pbar.set_postfix({
                    'train_loss': f'{avg_train_loss:.4f}',
                    'val_loss': f'{avg_val_loss:.4f}',
                    'accuracy': f'{current_accuracy:.4f}',
                    'lr': f'{current_lr:.1e}'
                })
                pbar.update(1)
                
                # Early stopping check
                if avg_val_loss < best_val_loss - 0.0005:
                    best_val_loss = avg_val_loss
                    patience_counter = 0
                else:
                    patience_counter += 1
                
                if patience_counter >= 8:
                    print(f"\nüõë Model {i+1} stopped early at epoch {epoch + 1}")
                    individual_stats['early_stopped'] = True
                    break
                
                # Memory cleanup
                if torch.cuda.is_available():
                    torch.cuda.empty_cache()
        
        # Final validation for ensemble weighting
        model.eval()
        final_correct = 0
        final_total = 0
        final_loss = 0
        final_batches = 0
        
        with torch.no_grad():
            for X_batch, y_direction_batch, y_price_batch in val_loader:
                X_batch = X_batch.to(device)
                y_direction_batch = y_direction_batch.to(device)
                y_price_batch = y_price_batch.to(device)
                
                try:
                    direction_outputs, price_outputs, dir_unc, price_unc = model(X_batch)
                    
                    if not (torch.isnan(direction_outputs).any() or torch.isnan(price_outputs).any()):
                        direction_loss = direction_criterion(direction_outputs, y_direction_batch)
                        price_loss = price_criterion(price_outputs.squeeze(), y_price_batch)
                        total_loss = direction_loss + 0.05 * price_loss
                        
                        if not torch.isnan(total_loss):
                            final_loss += total_loss.item()
                            _, predicted = torch.max(direction_outputs.data, 1)
                            final_total += y_direction_batch.size(0)
                            final_correct += (predicted == y_direction_batch).sum().item()
                            final_batches += 1
                except:
                    continue
        
        final_accuracy = final_correct / final_total if final_total > 0 else 0
        final_avg_loss = final_loss / final_batches if final_batches > 0 else float('inf')
        
        validation_accuracies.append(final_accuracy)
        validation_losses.append(final_avg_loss)
        model_stats.append(individual_stats)
        
        print(f"‚úÖ Model {i+1} final validation accuracy: {final_accuracy:.4f}")
        print(f"üìä Model {i+1} final validation loss: {final_avg_loss:.4f}")
        
        # Memory cleanup
        if torch.cuda.is_available():
            torch.cuda.empty_cache()
    
    return model_stats, validation_accuracies, validation_losses

if __name__ == '__main__':
    main() 