{
    "model_type": "Multi-Task LSTM+Attention (RTX 3060 Optimized)",
    "device": "cuda",
    "gpu_name": "NVIDIA GeForce RTX 3060",
    "direction_accuracy": 0.28275488907783874,
    "price_mse": 0.003179656776113053,
    "price_r2": -9.791737184797467,
    "training_time": 137.70329332351685,
    "inference_time": 1.7387299537658691,
    "parameters": 674372,
    "batch_size": 2048,
    "gradient_accumulation_steps": 2,
    "effective_batch_size": 4096,
    "epochs_planned": 50,
    "epochs_completed": 49,
    "early_stopped": true,
    "input_size": 2900,
    "architecture": "BiLSTM + Attention + Multi-Task Head",
    "tasks": [
        "direction_classification",
        "price_regression"
    ],
    "optimizations": [
        "Mixed Precision (AMP)",
        "Learning Rate Finder",
        "Early Stopping",
        "Gradient Accumulation",
        "TorchScript Compilation",
        "OneCycleLR Scheduling"
    ],
    "training_curves": {
        "train_losses": [
            1.2961333831151327,
            1.2951465447743733,
            1.298523203531901,
            1.2962406317392985,
            1.2983596007029214,
            1.2959927399953206,
            1.2978412946065268,
            1.2970495541890463,
            1.2937683900197348,
            1.2946583906809488,
            1.2952720801035562,
            1.2924972534179688,
            1.291312026977539,
            1.2905219078063965,
            1.2934241056442262,
            1.2913800716400146,
            1.2895280043284099,
            1.2878514925638835,
            1.2874449412027995,
            1.2879292726516725,
            1.2872867504755656,
            1.2827477296193441,
            1.2850913127263388,
            1.2861412604649862,
            1.2837316274642945,
            1.2870087941487631,
            1.286898954709371,
            1.2863849719365439,
            1.2835045099258422,
            1.2803882122039796,
            1.2819840431213378,
            1.2807173569997152,
            1.284817131360372,
            1.2835360447565713,
            1.2814628203709921,
            1.282173212369283,
            1.2789076169331868,
            1.2862596035003662,
            1.2818076133728027,
            1.2849262952804565,
            1.2805720806121825,
            1.279040241241455,
            1.2803184986114502,
            1.2825290203094482,
            1.2826214154561362,
            1.2793803135553996,
            1.2812995910644531,
            1.2826478242874146,
            1.2802954991658528
        ],
        "val_losses": [
            1.2782069274357386,
            1.2931370905467443,
            1.2988471473966325,
            1.312278423990522,
            1.299405472619193,
            1.2612563712256295,
            1.2406130177634103,
            1.2365928888320923,
            1.235451238495963,
            1.2346738576889038,
            1.2341323409761702,
            1.2337775911603654,
            1.2343670300074987,
            1.2327747344970703,
            1.2325191838400704,
            1.2332769291741508,
            1.232505440711975,
            1.231403453009469,
            1.231568557875497,
            1.2313825402941023,
            1.230343563216073,
            1.2308092287608556,
            1.2305061987468175,
            1.2303979226521082,
            1.2299468687602453,
            1.2294089964457922,
            1.2294035128184728,
            1.2280256237302507,
            1.2290738821029663,
            1.2290141071592058,
            1.229233639580863,
            1.2293649571282523,
            1.2293419667652674,
            1.2284902504512243,
            1.2283478804997034,
            1.2281090702329363,
            1.2277102981294905,
            1.2277048315320696,
            1.2270661081586565,
            1.2279088837759835,
            1.2274555138179235,
            1.2285112312861852,
            1.2275100265230452,
            1.2280774797712053,
            1.2276087829044886,
            1.2282385655811854,
            1.2276154926845007,
            1.2279961279460363,
            1.2274526868547713
        ],
        "learning_rates": [
            1.4522881713906707e-08,
            2.3575350154562943e-08,
            3.821406358096803e-08,
            5.7786923416382867e-08,
            8.142203377285569e-08,
            1.0806654107127855e-07,
            1.3653353463302073e-07,
            1.6555491900153972e-07,
            1.9383790273468788e-07,
            2.2012258730852453e-07,
            2.432380907676916e-07,
            2.621547060288371e-07,
            2.760297703845771e-07,
            2.842452028974009e-07,
            2.8648599917313376e-07,
            2.857447216734797e-07,
            2.838561561199242e-07,
            2.8083550813184584e-07,
            2.7670709819073245e-07,
            2.715041658259641e-07,
            2.6526860198966726e-07,
            2.580506117753995e-07,
            2.4990831019625674e-07,
            2.409072542769584e-07,
            2.3111991522723144e-07,
            2.2062509494624213e-07,
            2.095072915560386e-07,
            1.978560190723563e-07,
            1.8576508669039643e-07,
            1.7333184348834554e-07,
            1.606563946298379e-07,
            1.4784079537603896e-07,
            1.3498822939668994e-07,
            1.2220217799587017e-07,
            1.0958558694138262e-07,
            9.724003760596261e-08,
            8.526492909379344e-08,
            7.375667793736533e-08,
            6.280794180824777e-08,
            5.2506873491999866e-08,
            4.2936411133773836e-08,
            3.41736104691374e-08,
            2.628902441659895e-08,
            1.934613502699195e-08,
            1.3400842363328686e-08,
            8.501014426361481e-09,
            4.68610174958661e-09,
            1.9868197667451737e-09,
            4.2490150921087725e-10
        ]
    }
}